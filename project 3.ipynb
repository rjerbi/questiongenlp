{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4bd406",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-14T19:19:20.379302Z",
     "iopub.status.busy": "2025-04-14T19:19:20.378972Z",
     "iopub.status.idle": "2025-04-14T19:19:58.899179Z",
     "shell.execute_reply": "2025-04-14T19:19:58.898008Z"
    },
    "papermill": {
     "duration": 38.527243,
     "end_time": "2025-04-14T19:19:58.901113",
     "exception": false,
     "start_time": "2025-04-14T19:19:20.373870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[bag] in /usr/local/lib/python3.11/dist-packages (2024.12.1)\r\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (8.1.8)\r\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (3.1.1)\r\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (2025.3.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (24.2)\r\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (1.4.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (6.0.2)\r\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (1.0.0)\r\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask[bag]) (8.6.1)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask[bag]) (3.21.0)\r\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask[bag]) (1.0.0)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\r\n",
      "Collecting yake\r\n",
      "  Downloading yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from yake) (0.9.0)\r\n",
      "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.11/dist-packages (from yake) (8.1.8)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from yake) (1.26.4)\r\n",
      "Collecting segtok (from yake)\r\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from yake) (3.4.2)\r\n",
      "Requirement already satisfied: jellyfish in /usr/local/lib/python3.11/dist-packages (from yake) (1.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->yake) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->yake) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->yake) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->yake) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->yake) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->yake) (2.4.1)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from segtok->yake) (2024.11.6)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->yake) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->yake) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->yake) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->yake) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->yake) (2024.2.0)\r\n",
      "Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\r\n",
      "Installing collected packages: segtok, yake\r\n",
      "Successfully installed segtok-1.5.11 yake-0.4.8\r\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\r\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\r\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\r\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\r\n",
      "order to load all the package's dependencies. You can do this by selecting the\r\n",
      "'Restart kernel' or 'Restart runtime' option.\r\n"
     ]
    }
   ],
   "source": [
    "# Dependencies Installation\n",
    "!pip install dask[bag]        # For loading and processing large JSON files in parallel (arXiv data).\n",
    "!pip install nltk             # For text preprocessing (stopwords like a,the,of.. removal).\n",
    "!pip install yake             # For extracting keywords (concepts) from abstracts.\n",
    "!pip install spacy            # For Named Entity Recognition (NER) using `en_core_web_sm`.\n",
    "!pip install scikit-learn     # For ML tasks if extended.\n",
    "!pip install transformers     # For question generation using pre-trained T5 model.\n",
    "!python -m spacy download en_core_web_sm  # English model for spaCy (used to extract named entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44865f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:19:58.913804Z",
     "iopub.status.busy": "2025-04-14T19:19:58.913481Z",
     "iopub.status.idle": "2025-04-14T19:22:04.898294Z",
     "shell.execute_reply": "2025-04-14T19:22:04.897331Z"
    },
    "papermill": {
     "duration": 125.997601,
     "end_time": "2025-04-14T19:22:04.904651",
     "exception": false,
     "start_time": "2025-04-14T19:19:58.907050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>2008-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0046</td>\n",
       "      <td>A limit relation for entropy and channel capac...</td>\n",
       "      <td>In a quantum mechanical model, Diosi, Feldma...</td>\n",
       "      <td>quant-ph cs.IT math.IT</td>\n",
       "      <td>2009-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0047</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>The intelligent acoustic emission locator is...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>2009-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0050</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>Part I describes an intelligent acoustic emi...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>2007-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0062</td>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship...</td>\n",
       "      <td>In this paper, we introduce the on-line Vite...</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>2010-01-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "1  0704.0046  A limit relation for entropy and channel capac...   \n",
       "2  0704.0047  Intelligent location of simultaneously active ...   \n",
       "3  0704.0050  Intelligent location of simultaneously active ...   \n",
       "4  0704.0062  On-line Viterbi Algorithm and Its Relationship...   \n",
       "\n",
       "                                            abstract              categories  \\\n",
       "0    We describe a new algorithm, the $(k,\\ell)$-...           math.CO cs.CG   \n",
       "1    In a quantum mechanical model, Diosi, Feldma...  quant-ph cs.IT math.IT   \n",
       "2    The intelligent acoustic emission locator is...             cs.NE cs.AI   \n",
       "3    Part I describes an intelligent acoustic emi...             cs.NE cs.AI   \n",
       "4    In this paper, we introduce the on-line Vite...                   cs.DS   \n",
       "\n",
       "  update_date  \n",
       "0  2008-12-13  \n",
       "1  2009-11-13  \n",
       "2  2009-09-29  \n",
       "3  2007-05-23  \n",
       "4  2010-01-25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Loading and Filtering\n",
    "import dask.bag as db\n",
    "import json\n",
    "\n",
    "# Load JSON data with Dask and parse each line as a JSON object\n",
    "docs = db.read_text('/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json').map(json.loads)\n",
    "\n",
    "# Keep only Computer Science articles\n",
    "def trim(x):\n",
    "    return {\n",
    "        'id': x['id'],\n",
    "        'title': x['title'],\n",
    "        'abstract': x['abstract'],\n",
    "        'categories': x['categories'],\n",
    "        'update_date': x['update_date']\n",
    "    }\n",
    "\n",
    "docs_cs = (docs\n",
    "           .filter(lambda x: \"cs\" in str(x[\"categories\"]) and \"physics\" not in str(x[\"categories\"]))\n",
    "           .map(trim)\n",
    "           .compute())\n",
    "\n",
    "#Data Preprocessing\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(docs_cs)\n",
    "df = df.dropna(subset=[\"abstract\"]).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88e7132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:22:04.916421Z",
     "iopub.status.busy": "2025-04-14T19:22:04.915837Z",
     "iopub.status.idle": "2025-04-14T19:23:17.824752Z",
     "shell.execute_reply": "2025-04-14T19:23:17.823652Z"
    },
    "papermill": {
     "duration": 72.921752,
     "end_time": "2025-04-14T19:23:17.831476",
     "exception": false,
     "start_time": "2025-04-14T19:22:04.909724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>describe new algorithm kellpebble game colors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a quantum mechanical model, Diosi, Feldma...</td>\n",
       "      <td>quantum mechanical model diosi feldmann koslof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The intelligent acoustic emission locator is...</td>\n",
       "      <td>intelligent acoustic emission locator describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Part I describes an intelligent acoustic emi...</td>\n",
       "      <td>part describes intelligent acoustic emission l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this paper, we introduce the on-line Vite...</td>\n",
       "      <td>paper introduce online viterbi algorithm decod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "1    In a quantum mechanical model, Diosi, Feldma...   \n",
       "2    The intelligent acoustic emission locator is...   \n",
       "3    Part I describes an intelligent acoustic emi...   \n",
       "4    In this paper, we introduce the on-line Vite...   \n",
       "\n",
       "                                    cleaned_abstract  \n",
       "0  describe new algorithm kellpebble game colors ...  \n",
       "1  quantum mechanical model diosi feldmann koslof...  \n",
       "2  intelligent acoustic emission locator describe...  \n",
       "3  part describes intelligent acoustic emission l...  \n",
       "4  paper introduce online viterbi algorithm decod...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Data\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Clean abstract: lowercase, remove punctuation, remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['cleaned_abstract'] = df['abstract'].apply(clean_text)\n",
    "df[['abstract', 'cleaned_abstract']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "158425a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:23:17.843772Z",
     "iopub.status.busy": "2025-04-14T19:23:17.843117Z",
     "iopub.status.idle": "2025-04-14T19:24:38.082803Z",
     "shell.execute_reply": "2025-04-14T19:24:38.081846Z"
    },
    "papermill": {
     "duration": 80.253227,
     "end_time": "2025-04-14T19:24:38.090035",
     "exception": false,
     "start_time": "2025-04-14T19:23:17.836808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>concepts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555077</th>\n",
       "      <td>raman spectroscopy photonic modality based ine...</td>\n",
       "      <td>[raman, achieve, sers, system, spectroscopy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394218</th>\n",
       "      <td>paper propose gametheoretic solution parking p...</td>\n",
       "      <td>[paper, space, solution, parking, approach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325072</th>\n",
       "      <td>wellknown fractal signals appear many fields s...</td>\n",
       "      <td>[traffic, signals, computer, flows, results]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494267</th>\n",
       "      <td>motivated various computational applications i...</td>\n",
       "      <td>[nested, expectations, estimator, motivated, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457170</th>\n",
       "      <td>reproduction numbers widely used estimation pr...</td>\n",
       "      <td>[reproduction, numbers, distributed, spreading...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_abstract  \\\n",
       "555077  raman spectroscopy photonic modality based ine...   \n",
       "394218  paper propose gametheoretic solution parking p...   \n",
       "325072  wellknown fractal signals appear many fields s...   \n",
       "494267  motivated various computational applications i...   \n",
       "457170  reproduction numbers widely used estimation pr...   \n",
       "\n",
       "                                                 concepts  \n",
       "555077       [raman, achieve, sers, system, spectroscopy]  \n",
       "394218        [paper, space, solution, parking, approach]  \n",
       "325072       [traffic, signals, computer, flows, results]  \n",
       "494267  [nested, expectations, estimator, motivated, s...  \n",
       "457170  [reproduction, numbers, distributed, spreading...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keyword Extraction with YAKE\n",
    "import yake\n",
    "\n",
    "# Sample 10,000 abstracts to reduce processing time\n",
    "sample_df = df.sample(10000, random_state=42)\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=5)\n",
    "\n",
    "# Extract top 5 single-word keywords from each abstract\n",
    "sample_df['concepts'] = sample_df['cleaned_abstract'].apply(lambda x: [kw[0] for kw in kw_extractor.extract_keywords(x)])\n",
    "\n",
    "sample_df[['cleaned_abstract', 'concepts']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3431e2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:24:38.102326Z",
     "iopub.status.busy": "2025-04-14T19:24:38.101673Z",
     "iopub.status.idle": "2025-04-14T19:28:45.289080Z",
     "shell.execute_reply": "2025-04-14T19:28:45.288181Z"
    },
    "papermill": {
     "duration": 247.201586,
     "end_time": "2025-04-14T19:28:45.296984",
     "exception": false,
     "start_time": "2025-04-14T19:24:38.095398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555077</th>\n",
       "      <td>Raman spectroscopy, a photonic modality base...</td>\n",
       "      <td>[(Raman, PERSON), (Surface-Enhanced Raman, ORG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394218</th>\n",
       "      <td>In this paper, we propose a game-theoretic s...</td>\n",
       "      <td>[(Nash, ORG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325072</th>\n",
       "      <td>It is well-known that fractal signals appear...</td>\n",
       "      <td>[(LAN, ORG), (WWW, ORG), (VBR, ORG), (first, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494267</th>\n",
       "      <td>Motivated by various computational applicati...</td>\n",
       "      <td>[(Monte Carlo, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457170</th>\n",
       "      <td>Reproduction numbers are widely used for the...</td>\n",
       "      <td>[(SIS, ORG), (SIR, ORG)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract  \\\n",
       "555077    Raman spectroscopy, a photonic modality base...   \n",
       "394218    In this paper, we propose a game-theoretic s...   \n",
       "325072    It is well-known that fractal signals appear...   \n",
       "494267    Motivated by various computational applicati...   \n",
       "457170    Reproduction numbers are widely used for the...   \n",
       "\n",
       "                                                 entities  \n",
       "555077  [(Raman, PERSON), (Surface-Enhanced Raman, ORG...  \n",
       "394218                                      [(Nash, ORG)]  \n",
       "325072  [(LAN, ORG), (WWW, ORG), (VBR, ORG), (first, O...  \n",
       "494267                            [(Monte Carlo, PERSON)]  \n",
       "457170                           [(SIS, ORG), (SIR, ORG)]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition with spaCy\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "texts = sample_df['abstract'].tolist()\n",
    "entities = []\n",
    "\n",
    "# Extract named entities from each abstract\n",
    "for doc in nlp.pipe(texts, batch_size=50):\n",
    "    ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    entities.append(ents)\n",
    "\n",
    "sample_df['entities'] = entities\n",
    "sample_df[['abstract', 'entities']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81bf201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:28:45.311136Z",
     "iopub.status.busy": "2025-04-14T19:28:45.310312Z",
     "iopub.status.idle": "2025-04-14T19:29:16.555251Z",
     "shell.execute_reply": "2025-04-14T19:29:16.554140Z"
    },
    "papermill": {
     "duration": 31.253522,
     "end_time": "2025-04-14T19:29:16.556685",
     "exception": false,
     "start_time": "2025-04-14T19:28:45.303163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:28:53.439210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744658933.645423      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744658933.707194      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ad921296aa4e8d8dd008873d5a39b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f814308c972b4e2581a318a65819294d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4082d298ead14a278a607bb77b25d1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b67aab2f64133bccc457519e09a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a86e9728cbe47cebf0f68376ba79f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cba84d5dd945feb9d3c59c4523fdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b5d5cbfc424790aa54e807f1553d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword : raman\n",
      "Generated Question : What is the spectroscopy algorithm that uses metal nanostructures to detect a weak tissue?\n"
     ]
    }
   ],
   "source": [
    "# Question Generation with Hugging Face Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained T5 question generator\n",
    "qg = pipeline(\"text2text-generation\", model=\"valhalla/t5-small-qa-qg-hl\")\n",
    "\n",
    "def generate_question(text, keyword):\n",
    "    highlighted = text.replace(keyword, f\"<hl>{keyword}<hl>\")\n",
    "    input_text = f\"generate question: {highlighted}\"\n",
    "    output = qg(input_text, max_length=64)[0]['generated_text']\n",
    "    return output\n",
    "\n",
    "# Highlight a keyword and generate a question about it (example)\n",
    "text_sample = sample_df.iloc[0]['cleaned_abstract']\n",
    "keyword_sample = sample_df.iloc[0]['concepts'][0]\n",
    "print(\"Keyword :\", keyword_sample)\n",
    "print(\"Generated Question :\", generate_question(text_sample, keyword_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d0b8cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:29:16.571882Z",
     "iopub.status.busy": "2025-04-14T19:29:16.570976Z",
     "iopub.status.idle": "2025-04-14T19:30:12.112221Z",
     "shell.execute_reply": "2025-04-14T19:30:12.111354Z"
    },
    "papermill": {
     "duration": 55.556658,
     "end_time": "2025-04-14T19:30:12.120153",
     "exception": false,
     "start_time": "2025-04-14T19:29:16.563495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>concepts</th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555077</th>\n",
       "      <td>raman spectroscopy photonic modality based ine...</td>\n",
       "      <td>[raman, achieve, sers, system, spectroscopy]</td>\n",
       "      <td>[What is the spectroscopy algorithm that uses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394218</th>\n",
       "      <td>paper propose gametheoretic solution parking p...</td>\n",
       "      <td>[paper, space, solution, parking, approach]</td>\n",
       "      <td>[What paper propose gametheoretic solution par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325072</th>\n",
       "      <td>wellknown fractal signals appear many fields s...</td>\n",
       "      <td>[traffic, signals, computer, flows, results]</td>\n",
       "      <td>[What is the name of the flow of fractal signa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494267</th>\n",
       "      <td>motivated various computational applications i...</td>\n",
       "      <td>[nested, expectations, estimator, motivated, s...</td>\n",
       "      <td>[What is the expected outcome of a novel monte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457170</th>\n",
       "      <td>reproduction numbers widely used estimation pr...</td>\n",
       "      <td>[reproduction, numbers, distributed, spreading...</td>\n",
       "      <td>[What type of numbers provide finegrained anal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_abstract  \\\n",
       "555077  raman spectroscopy photonic modality based ine...   \n",
       "394218  paper propose gametheoretic solution parking p...   \n",
       "325072  wellknown fractal signals appear many fields s...   \n",
       "494267  motivated various computational applications i...   \n",
       "457170  reproduction numbers widely used estimation pr...   \n",
       "\n",
       "                                                 concepts  \\\n",
       "555077       [raman, achieve, sers, system, spectroscopy]   \n",
       "394218        [paper, space, solution, parking, approach]   \n",
       "325072       [traffic, signals, computer, flows, results]   \n",
       "494267  [nested, expectations, estimator, motivated, s...   \n",
       "457170  [reproduction, numbers, distributed, spreading...   \n",
       "\n",
       "                                                questions  \n",
       "555077  [What is the spectroscopy algorithm that uses ...  \n",
       "394218  [What paper propose gametheoretic solution par...  \n",
       "325072  [What is the name of the flow of fractal signa...  \n",
       "494267  [What is the expected outcome of a novel monte...  \n",
       "457170  [What type of numbers provide finegrained anal...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch Question Generation\n",
    "\n",
    "# Make sure concepts are lists\n",
    "sample_df['concepts'] = sample_df['concepts'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Generate up to 3 questions per abstract using the top keywords\n",
    "def gen_qs(row):\n",
    "    abstract = row['cleaned_abstract']\n",
    "    keywords = row['concepts'][:3]\n",
    "    questions = []\n",
    "    for kw in keywords:\n",
    "        try:\n",
    "            q = generate_question(abstract, kw)\n",
    "            questions.append(q)\n",
    "        except Exception as e:\n",
    "            questions.append(f\"Error: {str(e)}\")\n",
    "    return questions\n",
    "\n",
    "# Apply to a small sample (100) for quick testing\n",
    "sample_df = sample_df.head(100)  # pour tester rapidement\n",
    "sample_df['questions'] = sample_df.apply(gen_qs, axis=1)\n",
    "\n",
    "# Print result of quick testing \n",
    "sample_df[['cleaned_abstract', 'concepts', 'questions']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7d60eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:30:12.135443Z",
     "iopub.status.busy": "2025-04-14T19:30:12.135131Z",
     "iopub.status.idle": "2025-04-14T19:30:12.157534Z",
     "shell.execute_reply": "2025-04-14T19:30:12.156674Z"
    },
    "papermill": {
     "duration": 0.037577,
     "end_time": "2025-04-14T19:30:12.164030",
     "exception": false,
     "start_time": "2025-04-14T19:30:12.126453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Abstract 555077:\n",
      "  Raman spectroscopy, a photonic modality based on the inelastic backscattering\n",
      "of coherent light, is a valuable asset to the intraoperative sensing space,\n",
      "offering non-ionizing potential and highly-specific molecular fingerprint-like\n",
      "spectroscopic signatures that can be used for diagnosis of pathological tissue\n",
      "in the dynamic surgical field. Though Raman suffers from weakness in intensity,\n",
      "Surface-Enhanced Raman Spectroscopy (SERS), which uses metal nanostructures to\n",
      "amplify Raman signals, can achieve detection sensitivities that rival\n",
      "traditional photonic modalities. In this study, we outline a robotic Raman\n",
      "system that can reliably pinpoint the location and boundaries of a tumor\n",
      "embedded in healthy tissue, modeled here as a tissue-mimicking phantom with\n",
      "selectively infused Gold Nanostar regions. Further, due to the relative dearth\n",
      "of collected biological SERS or Raman data, we implement transfer learning to\n",
      "achieve 100% validation classification accuracy for Gold Nanostars compared to\n",
      "Control Agarose, thus providing a proof-of-concept for Raman-based deep\n",
      "learning training pipelines. We reconstruct a surgical field of 30x60mm in 10.2\n",
      "minutes, and achieve 98.2% accuracy, preserving relative measurements between\n",
      "features in the phantom. We also achieve an 84.3% Intersection-over-Union\n",
      "score, which is the extent of overlap between the ground truth and predicted\n",
      "reconstructions. Lastly, we also demonstrate that the Raman system and\n",
      "classification algorithm do not discern based on sample color, but instead on\n",
      "presence of SERS agents. This study provides a crucial step in the translation\n",
      "of intelligent Raman systems in intraoperative oncological spaces.\n",
      "\n",
      "\n",
      " Concepts: raman, achieve, sers, system, spectroscopy\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the spectroscopy algorithm that uses metal nanostructures to detect a weak tissue?\n",
      "  2. What achieved 982 accuracy preserving relative measurements features phantom?\n",
      "  3. What is the name of the agent that uses metal nanostructures to detect raman signals?\n",
      "================================================================================\n",
      "\n",
      " Abstract 394218:\n",
      "  In this paper, we propose a game-theoretic solution to the parking problem,\n",
      "by exploiting a strategic-reasoning approach for multi-agent systems.\n",
      "Precisely, cars are modeled by agents interacting among them in a multi-player\n",
      "game setting, whose aim is to get a free slot parking-place satisfying their\n",
      "own constraints. The overall assignment is then given as a Nash equilibrium\n",
      "solution. We come up with an algorithm (and its implementation in a tool) that\n",
      "works in quadratic time. We give evidence of the benefits of our approach by\n",
      "running our tool on a large hospital parking space.\n",
      "\n",
      "\n",
      " Concepts: paper, space, solution, parking, approach\n",
      "\n",
      " Generated Questions:\n",
      "  1. What paper propose gametheoretic solution parking problem exploiting strategicreasoning approach multiagent systems precisely cars modeled agents interacting among multiplayer game setting?\n",
      "  2. What is the large hospital parking a lot?\n",
      "  3. What is the aim of gametheoretic?\n",
      "================================================================================\n",
      "\n",
      " Abstract 325072:\n",
      "  It is well-known that fractal signals appear in many fields of science. LAN\n",
      "and WWW traces, wireless traffic, VBR resources, etc. are among the ones with\n",
      "this behavior in computer networks traffic flows. An important question in\n",
      "these applications is how long a measured trace should be to obtain reliable\n",
      "estimates of de Hurst index (H). This paper addresses this question by first\n",
      "providing a thorough study of estimator for short series based on the behavior\n",
      "of bias, standard deviation (s), Root-Mean-Square Error (RMSE), and convergence\n",
      "when using Gaussian H-Self-Similar with Stationary Increments signals (H-sssi\n",
      "signals). Results show that Whittle-type estimators behave the best when\n",
      "estimating H for short signals. Based on the results, empirically derived the\n",
      "minimum trace length for the estimators is proposed. Finally for testing the\n",
      "results, the application of estimators to real traces is accomplished.\n",
      "Immediate applications from this can be found in the real-time estimation of H\n",
      "which is useful in agent-based control of Quality of Service (QoS) parameters\n",
      "in the high-speed computer network traffic flows.\n",
      "\n",
      "\n",
      " Concepts: traffic, signals, computer, flows, results\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the name of the flow of fractal signals?\n",
      "  2. What are whittletype estimators best estimating h short?\n",
      "  3. What type of network traffic flows are important question applications long measured trace obtain reliable estimates de hurst index h paper addresses question?\n",
      "================================================================================\n",
      "\n",
      " Abstract 494267:\n",
      "  Motivated by various computational applications, we investigate the problem\n",
      "of estimating nested expectations. Building upon recent work by the authors, we\n",
      "propose a novel Monte Carlo estimator for nested expectations, inspired by\n",
      "sparse grid quadrature, that does not require sampling from inner conditional\n",
      "distributions. Theoretical analysis establishes an upper bound on the mean\n",
      "squared error of our estimator under mild assumptions on the problem,\n",
      "demonstrating its efficiency for cases with low-dimensional outer variables. We\n",
      "illustrate the effectiveness of our estimator through its application to\n",
      "problems related to value of information analysis, with moderate\n",
      "dimensionality. Overall, our method presents a promising approach to\n",
      "efficiently estimate nested expectations in practical computational settings.\n",
      "\n",
      "\n",
      " Concepts: nested, expectations, estimator, motivated, settings\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the expected outcome of a novel monte carlo estimator?\n",
      "  2. What is the result of a novel method to estimate?\n",
      "  3. What is the term for a novel monte carlo?\n",
      "================================================================================\n",
      "\n",
      " Abstract 457170:\n",
      "  Reproduction numbers are widely used for the estimation and prediction of\n",
      "epidemic spreading processes over networks. However, reproduction numbers do\n",
      "not enable estimation and prediction in individual communities within networks,\n",
      "and they can be difficult to compute due to the aggregation of infection data\n",
      "that is required to do so. Therefore, in this work we propose a novel concept\n",
      "of distributed reproduction numbers to capture the spreading behaviors of each\n",
      "entity in the network, and we show how to compute them using certain parameters\n",
      "in networked SIS and SIR epidemic models. We use distributed reproduction\n",
      "numbers to derive new conditions under which an outbreak can occur. These\n",
      "conditions are then used to derive new conditions for the existence,\n",
      "uniqueness, and stability of equilibrium states. Finally, in simulation we use\n",
      "synthetic infection data to illustrate how distributed reproduction numbers\n",
      "provide more fine-grained analyses of networked spreading processes than\n",
      "ordinary reproduction numbers.\n",
      "\n",
      "\n",
      " Concepts: reproduction, numbers, distributed, spreading, conditions\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of numbers provide finegrained analyses of the disease?\n",
      "  2. reproduce whose numbers derive new conditions outbreak occur conditions used derive new conditions existence uniqueness stability equilibrium states finally simulation use synthetic infection data illustrate distributed reproduction?\n",
      "  3. What type of reproduction numbers derive new conditions exist uniqueness stability equilibrium states finally simulation use synthetic infection data illustrate?\n",
      "================================================================================\n",
      "\n",
      " Abstract 415629:\n",
      "  MIT wanted to commission a large scale artwork that would serve to\n",
      "'illuminate a new campus gateway, inaugurate a space of exchange between MIT\n",
      "and Cambridge, and inspire our students, faculty, visitors, and the surrounding\n",
      "community to engage with art in new ways and to have art be part of their daily\n",
      "lives.' Among other things, the art was to reflect the fact that scientific\n",
      "discovery is often the result of many individual contributions, both\n",
      "acknowledged and unacknowledged. In this work, a group of computer scientists\n",
      "collaborated with a conceptual artist to produce a collective signature, or a\n",
      "signature learned from contributions of an entire community. After collecting\n",
      "signatures from two communities -- the university, and the surrounding city --\n",
      "the computer scientists developed generative models and a human-in-the-loop\n",
      "feedback process to work with the artist create an original signature-like\n",
      "structure representative of each community. These signatures are now\n",
      "large-scale steel, LED and neon light sculptures that appear to sign two new\n",
      "buildings in Cambridge, MA.\n",
      "\n",
      "\n",
      " Concepts: computer, scientists, community, art, mit\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of scientists collaborated conceptual artist produce collective signature signature learned contributions entire community collecting signatures two communities university surrounding city?\n",
      "  2. What scientists developed generative models humanintheloop feedback process work artist create original signaturelike structure?\n",
      "  3. What community does art reflect fact scientific discovery often result many individual contributions acknowledged unacknowledged work group computer scientists collaborate conceptual artist create collective signature signature learned contributions?\n",
      "================================================================================\n",
      "\n",
      " Abstract 110109:\n",
      "  A class of methods based on multichannel linear prediction (MCLP) can achieve\n",
      "effective blind dereverberation of a source, when the source is observed with a\n",
      "microphone array. We propose an inventive use of MCLP as a pre-processing step\n",
      "for blind source separation with a microphone array. We show theoretically\n",
      "that, under certain assumptions, such pre-processing reduces the original blind\n",
      "reverberant source separation problem to a non-reverberant one, which in turn\n",
      "can be effectively tackled using existing methods. We demonstrate our claims\n",
      "using real recordings obtained with an eight-microphone circular array in\n",
      "reverberant environments.\n",
      "\n",
      "\n",
      " Concepts: source, array, microphone, separation, blind\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the name of the type of separation microphone array?\n",
      "  2. What type of reverberant environments are mclp preprocessing?\n",
      "  3. What type of array reverberant environments are used to demonstrate claims using real recordings obtained?\n",
      "================================================================================\n",
      "\n",
      " Abstract 640843:\n",
      "  We show that a circuit walk from a given feasible point of a given linear\n",
      "program to an optimal point can be computed in polynomial time using only\n",
      "linear algebra operations and the solution of the single given linear program.\n",
      "  We also show that a Graver walk from a given feasible point of a given\n",
      "integer program to an optimal point is polynomial time computable using an\n",
      "integer programming oracle, but without such an oracle, it is hard to compute\n",
      "such a walk even if an optimal solution to the given program is given as well.\n",
      "  Combining our oracle algorithm with recent results on sparse integer\n",
      "programming, we also show that Graver walks from any point are polynomial time\n",
      "computable over matrices of bounded tree-depth and subdeterminants.\n",
      "\n",
      "\n",
      " Concepts: point, polynomial, time, program, show\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the polynomial time computable using integer programming oracle without oracle hard compute walk?\n",
      "  2. What is the term for time computable matrices bounded treedepth subdeterminants?\n",
      "  3. What is the computable matrices bounded treedepth subdeterminants?\n",
      "================================================================================\n",
      "\n",
      " Abstract 511634:\n",
      "  Automated dementia screening enables early detection and intervention,\n",
      "reducing costs to healthcare systems and increasing quality of life for those\n",
      "affected. Depression has shared symptoms with dementia, adding complexity to\n",
      "diagnoses. The research focus so far has been on binary classification of\n",
      "dementia (DEM) and healthy controls (HC) using speech from picture description\n",
      "tests from a single dataset. In this work, we apply established baseline\n",
      "systems to discriminate cognitive impairment in speech from the semantic Verbal\n",
      "Fluency Test and the Boston Naming Test using text, audio and emotion\n",
      "embeddings in a 3-class classification problem (HC vs. MCI vs. DEM). We perform\n",
      "cross-corpus and mixed-corpus experiments on two independently recorded German\n",
      "datasets to investigate generalization to larger populations and different\n",
      "recording conditions. In a detailed error analysis, we look at depression as a\n",
      "secondary diagnosis to understand what our classifiers actually learn.\n",
      "\n",
      "\n",
      " Concepts: dementia, systems, depression, classification, dem\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is automated reducing costs healthcare systems?\n",
      "  2. What is the primary healthcare system that reduces costs?\n",
      "  3. What is the primary diagnosis dementia adding complexity?\n",
      "================================================================================\n",
      "\n",
      " Abstract 125301:\n",
      "  Chemical multisensor devices need calibration algorithms to estimate gas\n",
      "concentrations. Their possible adoption as indicative air quality measurements\n",
      "devices poses new challenges due to the need to operate in continuous\n",
      "monitoring modes in uncontrolled environments. Several issues, including slow\n",
      "dynamics, continue to affect their real world performances. At the same time,\n",
      "the need for estimating pollutant concentrations on board the devices, espe-\n",
      "cially for wearables and IoT deployments, is becoming highly desirable. In this\n",
      "framework, several calibration approaches have been proposed and tested on a\n",
      "variety of proprietary devices and datasets; still, no thorough comparison is\n",
      "available to researchers. This work attempts a benchmarking of the most\n",
      "promising calibration algorithms according to recent literature with a focus on\n",
      "machine learning approaches. We test the techniques against absolute and\n",
      "dynamic performances, generalization capabilities and computational/storage\n",
      "needs using three different datasets sharing continuous monitoring operation\n",
      "methodology. Our results can guide researchers and engineers in the choice of\n",
      "optimal strategy. They show that non-linear multivariate techniques yield\n",
      "reproducible results, outperforming lin- ear approaches. Specifically, the\n",
      "Support Vector Regression method consistently shows good performances in all\n",
      "the considered scenarios. We highlight the enhanced suitability of shallow\n",
      "neural networks in a trade-off between performance and computational/storage\n",
      "needs. We confirm, on a much wider basis, the advantages of dynamic approaches\n",
      "with respect to static ones that only rely on instantaneous sensor array\n",
      "response. The latter have been shown to be best choice whenever prompt and\n",
      "precise response is needed.\n",
      "\n",
      "\n",
      " Concepts: calibration, devices, approaches, algorithms, continuous\n",
      "\n",
      " Generated Questions:\n",
      "  1. What algorithms estimate gas concentrations possible adoption indicative air quality measurements devices poses new challenges due need operate continuous monitoring modes uncontrolled environments?\n",
      "  2. What is a new challenge due to continuous monitoring modes?\n",
      "  3. What is the most widely used method to measure the performance of lin ear?\n",
      "================================================================================\n",
      "\n",
      " Abstract 398304:\n",
      "  This paper proposes matrix-scaled consensus algorithm, which generalizes the\n",
      "scaled consensus algorithm in \\cite{Roy2015scaled}. In (scalar) scaled\n",
      "consensus algorithms, the agents' states do not converge to a common value, but\n",
      "to different points along a straight line in the state space, which depends on\n",
      "the scaling factors and the initial states of the agents. In the matrix-scaled\n",
      "consensus algorithm, a positive/negative definite matrix weight is assigned to\n",
      "each agent. Each agent updates its state based on the product of the sum of\n",
      "relative matrix scaled states and the sign of the matrix weight. Under the\n",
      "proposed algorithm, each agent asymptotically converges to a final point\n",
      "differing with a common consensus point by the inverse of its own scaling\n",
      "matrix. Thus, the final states of the agents are not restricted to a straight\n",
      "line but are extended to an open subspace of the state-space. Convergence\n",
      "analysis of matrix-scaled consensus for single and double-integrator agents are\n",
      "studied in detail. Simulation results are given to support the analysis.\n",
      "\n",
      "\n",
      " Concepts: consensus, algorithm, matrixscaled, matrix, scaled\n",
      "\n",
      " Generated Questions:\n",
      "  1. What algorithm converges common value different points along straight line state space depends scaling factors?\n",
      "  2. What algorithm converges common value different points along straight line state space depends scaling factors?\n",
      "  3. What consensus algorithm generalizes scaled consensus algorithm citeroy2015scaled scalar scaled consensus algorithms agents states converge common value different points along straight line state space depends scaling factors initial states agents?\n",
      "================================================================================\n",
      "\n",
      " Abstract 208747:\n",
      "  Cardiovascular disorders account for nearly 1 in 3 deaths in the United\n",
      "States. Care for these disorders are often determined during visits to acute\n",
      "care facilities, such as hospitals. While the length of stay in these settings\n",
      "represents just a small proportion of patients' lives, they account for a\n",
      "disproportionately large amount of decision making. To overcome this bias\n",
      "towards data from acute care settings, there is a need for longitudinal\n",
      "monitoring in patients with cardiovascular disorders. Longitudinal monitoring\n",
      "can provide a more comprehensive picture of patient health, allowing for more\n",
      "informed decision making. This work surveys the current field of sensing\n",
      "technologies and machine learning analytics that exist in the field of remote\n",
      "monitoring for cardiovascular disorders. We highlight three primary needs in\n",
      "the design of new smart health technologies: 1) the need for sensing technology\n",
      "that can track longitudinal trends in signs and symptoms of the cardiovascular\n",
      "disorder despite potentially infrequent, noisy, or missing data measurements;\n",
      "2) the need for new analytic techniques that model data captured in a\n",
      "longitudinal, continual fashion to aid in the development of new risk\n",
      "prediction techniques and in tracking disease progression; and 3) the need for\n",
      "machine learning techniques that are personalized and interpretable, allowing\n",
      "for advancements in shared clinical decision making. We highlight these needs\n",
      "based upon the current state-of-the-art in smart health technologies and\n",
      "analytics and discuss the ample opportunities that exist in addressing all\n",
      "three needs in the development of smart health technologies and analytics\n",
      "applied to the field of cardiovascular disorders and care.\n",
      "\n",
      "\n",
      " Concepts: cardiovascular, health, disorders, technologies, care\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of disorder is there a need for longitudinal monitoring?\n",
      "  2. What is the new smart based on?\n",
      "  3. Cardiovascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular vascular \n",
      "================================================================================\n",
      "\n",
      " Abstract 633:\n",
      "  While the best known outerbound for the K user interference channel states\n",
      "that there cannot be more than K/2 degrees of freedom, it has been conjectured\n",
      "that in general the constant interference channel with any number of users has\n",
      "only one degree of freedom. In this paper, we explore the spatial degrees of\n",
      "freedom per orthogonal time and frequency dimension for the K user wireless\n",
      "interference channel where the channel coefficients take distinct values across\n",
      "frequency slots but are fixed in time. We answer five closely related\n",
      "questions. First, we show that K/2 degrees of freedom can be achieved by\n",
      "channel design, i.e. if the nodes are allowed to choose the best constant,\n",
      "finite and nonzero channel coefficient values. Second, we show that if channel\n",
      "coefficients can not be controlled by the nodes but are selected by nature,\n",
      "i.e., randomly drawn from a continuous distribution, the total number of\n",
      "spatial degrees of freedom for the K user interference channel is almost surely\n",
      "K/2 per orthogonal time and frequency dimension. Thus, only half the spatial\n",
      "degrees of freedom are lost due to distributed processing of transmitted and\n",
      "received signals on the interference channel. Third, we show that interference\n",
      "alignment and zero forcing suffice to achieve all the degrees of freedom in all\n",
      "cases. Fourth, we show that the degrees of freedom $D$ directly lead to an\n",
      "$\\mathcal{O}(1)$ capacity characterization of the form\n",
      "$C(SNR)=D\\log(1+SNR)+\\mathcal{O}(1)$ for the multiple access channel, the\n",
      "broadcast channel, the 2 user interference channel, the 2 user MIMO X channel\n",
      "and the 3 user interference channel with M>1 antennas at each node. Fifth, we\n",
      "characterize the degree of freedom benefits from cognitive sharing of messages\n",
      "on the 3 user interference channel.\n",
      "\n",
      "\n",
      " Concepts: channel, interference, freedom, degrees, user\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the second show interference alignment zero forcing?\n",
      "  2. What is the main reason for the degree freedom cases?\n",
      "  3. What does k user interference channel have?\n",
      "================================================================================\n",
      "\n",
      " Abstract 516207:\n",
      "  Large language models (LLM) not only have revolutionized the field of natural\n",
      "language processing (NLP) but also have the potential to reshape many other\n",
      "fields, e.g., recommender systems (RS). However, most of the related work\n",
      "treats an LLM as a component of the conventional recommendation pipeline (e.g.,\n",
      "as a feature extractor), which may not be able to fully leverage the generative\n",
      "power of LLM. Instead of separating the recommendation process into multiple\n",
      "stages, such as score computation and re-ranking, this process can be\n",
      "simplified to one stage with LLM: directly generating recommendations from the\n",
      "complete pool of items. This survey reviews the progress, methods, and future\n",
      "directions of LLM-based generative recommendation by examining three questions:\n",
      "1) What generative recommendation is, 2) Why RS should advance to generative\n",
      "recommendation, and 3) How to implement LLM-based generative recommendation for\n",
      "various RS tasks. We hope that this survey can provide the context and guidance\n",
      "needed to explore this interesting and emerging topic.\n",
      "\n",
      "\n",
      " Concepts: generative, recommendation, llm, llmbased, language\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of recommendation is 3 implement?\n",
      "  2. What is the main component of llmbased generative?\n",
      "  3. What component of generative power is able to fully leverage?\n",
      "================================================================================\n",
      "\n",
      " Abstract 161585:\n",
      "  Scaling problems have a rich and diverse history, and thereby have found\n",
      "numerous applications in several fields of science and engineering. For\n",
      "instance, the matrix scaling problem has had applications ranging from\n",
      "theoretical computer science to telephone forecasting, economics, statistics,\n",
      "optimization, among many other fields. Recently, a generalization of matrix\n",
      "scaling known as operator scaling has found applications in non-commutative\n",
      "algebra, invariant theory, combinatorics and algebraic complexity; and a\n",
      "further generalization (tensor scaling) has found more applications in quantum\n",
      "information theory, geometric complexity theory and invariant theory. In this\n",
      "survey, we will describe in detail the scaling problems mentioned above,\n",
      "showing how alternating minimization algorithms naturally arise in this\n",
      "setting, and we shall present a general framework to rigorously analyze such\n",
      "algorithms. These simple problems and algorithms are not just applicable to\n",
      "diverse mathematical and CS areas, but also serve to bring out deep connections\n",
      "between them. As this framework makes extensive use of concepts from invariant\n",
      "theory, we also provide a very gentle introduction to basic concepts of\n",
      "invariant theory and how they are used to analyze alternating minimization\n",
      "algorithms for the scaling problems. This survey is intended for a general\n",
      "computer science audience, and the only background required is basic knowledge\n",
      "of calculus and linear algebra, thereby making it accessible to graduate\n",
      "students and even to advanced undergraduates.\n",
      "\n",
      "\n",
      " Concepts: scaling, invariant, theory, problems, applications\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the term for the term \"regular complexity theory\"?\n",
      "  2. What theory provides gentle introduction basic concepts?\n",
      "  3. What is the term for the survey of detail scaling problems?\n",
      "================================================================================\n",
      "\n",
      " Abstract 485584:\n",
      "  When communicating with elders with cognitive impairment, cognitive\n",
      "stimulation (CS) help to maintain the cognitive health of elders. Data sparsity\n",
      "is the main challenge in building CS-based dialogue systems, particularly in\n",
      "the Chinese language. To fill this gap, we construct a Chinese CS conversation\n",
      "(CSConv) dataset, which contains about 2.6K groups of dialogues with CS\n",
      "principles and emotional support strategy labels. Making chit chat while\n",
      "providing emotional support is overlooked by the majority of existing cognitive\n",
      "dialogue systems. In this paper, we propose a multi-source knowledge fusion\n",
      "method for CS dialogue (CSD), to generate open-ended responses guided by the CS\n",
      "principle and emotional support strategy. We first use a progressive mask\n",
      "method based on external knowledge to learn encoders as effective classifiers,\n",
      "which is the prerequisite to predict the CS principle and emotional support\n",
      "strategy of the target response. Then a decoder interacts with the perceived CS\n",
      "principle and emotional support strategy to generate responses. Extensive\n",
      "experiments conducted on the CSConv dataset demonstrate the effectiveness of\n",
      "the proposed method, while there is still a large space for improvement\n",
      "compared to human performance.\n",
      "\n",
      "\n",
      " Concepts: emotional, support, principle, strategy, cognitive\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the primary support strategy for chit chat?\n",
      "  2. What strategy generates responses?\n",
      "  3. What principle does cs dialogue csd generate openended responses?\n",
      "================================================================================\n",
      "\n",
      " Abstract 333004:\n",
      "  Application domains of Bayesian optimization include optimizing black-box\n",
      "  functions or very complex functions. The functions we are interested in\n",
      "describe\n",
      "  complex real-world systems applied in industrial settings. Even though\n",
      "  they do have explicit representations, standard optimization\n",
      "  techniques fail to provide validated solutions and correctness\n",
      "  guarantees for them.\n",
      "  In this paper we present a combination of Bayesian optimisation and SMT-based\n",
      "constraint solving to achieve safe and stable solutions with optimality\n",
      "guarantees.\n",
      "\n",
      "\n",
      " Concepts: functions, bayesian, optimization, complex, solutions\n",
      "\n",
      " Generated Questions:\n",
      "  1. What are the applications bayesian optimization include?\n",
      "  2. What type of optimization is smtbased constraint solving?\n",
      "  3. What is the main function of a bayesian application domain?\n",
      "================================================================================\n",
      "\n",
      " Abstract 517300:\n",
      "  Learning-based techniques, especially advanced Large Language Models (LLMs)\n",
      "for code, have gained considerable popularity in various software engineering\n",
      "(SE) tasks. However, most existing works focus on designing better\n",
      "learning-based models and pay less attention to the properties of datasets.\n",
      "Learning-based models, including popular LLMs for code, heavily rely on data,\n",
      "and the data's properties (e.g., data distribution) could significantly affect\n",
      "their behavior. We conducted an exploratory study on the distribution of SE\n",
      "data and found that such data usually follows a skewed distribution (i.e.,\n",
      "long-tailed distribution) where a small number of classes have an extensive\n",
      "collection of samples, while a large number of classes have very few samples.\n",
      "We investigate three distinct SE tasks and analyze the impacts of long-tailed\n",
      "distribution on the performance of LLMs for code. Our experimental results\n",
      "reveal that the long-tailed distribution has a substantial impact on the\n",
      "effectiveness of LLMs for code. Specifically, LLMs for code perform between\n",
      "30.0\\% and 254.0\\% worse on data samples associated with infrequent labels\n",
      "compared to data samples of frequent labels. Our study provides a better\n",
      "understanding of the effects of long-tailed distributions on popular LLMs for\n",
      "code and insights for the future development of SE automation.\n",
      "\n",
      "\n",
      " Concepts: llms, code, distribution, longtailed, data\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of code did learningbased models gain considerable popularity?\n",
      "  2. What is the name of the code that gained considerable popularity?\n",
      "  3. What could significantly affect behavior conducted exploratory study?\n",
      "================================================================================\n",
      "\n",
      " Abstract 88026:\n",
      "  In this paper, we study and analyze cooperative cognitive radio networks with\n",
      "arbitrary number of secondary users (SUs). Each SU is considered a prospective\n",
      "relay for the primary user (PU) besides having its own data transmission\n",
      "demand. We consider a multi-packet transmission framework which allows multiple\n",
      "SUs to transmit simultaneously thanks to dirty-paper coding. We propose power\n",
      "allocation and scheduling policies that optimize the throughput for both PU and\n",
      "SU with minimum energy expenditure. The performance of the system is evaluated\n",
      "in terms of throughput and delay under different opportunistic relay selection\n",
      "policies. Towards this objective, we present a mathematical framework for\n",
      "deriving stability conditions for all queues in the system. Consequently, the\n",
      "throughput of both primary and secondary links is quantified. Furthermore, a\n",
      "moment generating function (MGF) approach is employed to derive a closed-form\n",
      "expression for the average delay encountered by the PU packets. Results reveal\n",
      "that we achieve better performance in terms of throughput and delay at lower\n",
      "energy cost as compared to equal power allocation schemes proposed earlier in\n",
      "literature. Extensive simulations are conducted to validate our theoretical\n",
      "findings.\n",
      "\n",
      "\n",
      " Concepts: throughput, delay, power, allocation, terms\n",
      "\n",
      " Generated Questions:\n",
      "  1. What delay is opportunistic relay selection policies towards objective present mathematical framework deriving stability conditions queues system consequently ?\n",
      "  2. What is the result of a better performance terms throughput?\n",
      "  3. What does dirtypaper coding propose?\n",
      "================================================================================\n",
      "\n",
      " Abstract 268177:\n",
      "  Most of the saliency methods are evaluated on their ability to generate\n",
      "saliency maps, and not on their functionality in a complete vision pipeline,\n",
      "like for instance, image classification. In the current paper, we propose an\n",
      "approach which does not require explicit saliency maps to improve image\n",
      "classification, but they are learned implicitely, during the training of an\n",
      "end-to-end image classification task. We show that our approach obtains similar\n",
      "results as the case when the saliency maps are provided explicitely. Combining\n",
      "RGB data with saliency maps represents a significant advantage for object\n",
      "recognition, especially for the case when training data is limited. We validate\n",
      "our method on several datasets for fine-grained classification tasks (Flowers,\n",
      "Birds and Cars). In addition, we show that our saliency estimation method,\n",
      "which is trained without any saliency groundtruth data, obtains competitive\n",
      "results on real image saliency benchmark (Toronto), and outperforms deep\n",
      "saliency models with synthetic images (SID4VAM).\n",
      "\n",
      "\n",
      " Concepts: saliency, classification, maps, image, data\n",
      "\n",
      " Generated Questions:\n",
      "  1. What sort of maps does toronto outperform?\n",
      "  2. What is the task show approach that obtains similar results case saliency maps?\n",
      "  3. What is a significant advantage object recognition?\n",
      "================================================================================\n",
      "\n",
      " Abstract 249385:\n",
      "  We investigate the proof complexity of extended Frege (EF) systems for basic\n",
      "transitive modal logics (K4, S4, GL, ...) augmented with the bounded branching\n",
      "axioms $\\mathbf{BB}_k$. First, we study feasibility of the disjunction property\n",
      "and more general extension rules in EF systems for these logics: we show that\n",
      "the corresponding decision problems reduce to total coNP search problems (or\n",
      "equivalently, disjoint NP pairs, in the binary case); more precisely, the\n",
      "decision problem for extension rules is equivalent to a certain special case of\n",
      "interpolation for the classical EF system. Next, we use this characterization\n",
      "to prove superpolynomial (or even exponential, with stronger hypotheses)\n",
      "separations between EF and substitution Frege (SF) systems for all transitive\n",
      "logics contained in $\\mathbf{S4.2GrzBB_2}$ or $\\mathbf{GL.2BB_2}$ under some\n",
      "assumptions weaker than $\\mathrm{PSPACE \\ne NP}$. We also prove analogous\n",
      "results for superintuitionistic logics: we characterize the decision complexity\n",
      "of multi-conclusion Visser's rules in EF systems for Gabbay--de Jongh logics\n",
      "$\\mathbf T_k$, and we show conditional separations between EF and SF for all\n",
      "intermediate logics contained in $\\mathbf{T_2 + KC}$.\n",
      "\n",
      "\n",
      " Concepts: logics, systems, contained, rules, decision\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the term for a corresponding decision problem?\n",
      "  2. What types of logics show corresponding decision problems reduce total conp search problems?\n",
      "  3. What was the term for the term \"seconclusion vissers\"?\n",
      "================================================================================\n",
      "\n",
      " Abstract 44186:\n",
      "  Given a string $P$ of length $m$ over an alphabet $\\Sigma$ of size $\\sigma$,\n",
      "a swapped version of $P$ is a string derived from $P$ by a series of local\n",
      "swaps, i.e., swaps of adjacent symbols, such that each symbol can participate\n",
      "in at most one swap. We present a theoretical analysis of the nondeterministic\n",
      "finite automaton for the language $\\bigcup_{P'\\in\\Pi_P}\\Sigma^*P'$ (swap\n",
      "automaton for short), where $\\Pi_P$ is the set of swapped versions of $P$. Our\n",
      "study is based on the bit-parallel simulation of the same automaton due to\n",
      "Fredriksson, and reveals an interesting combinatorial property that links the\n",
      "automaton to the one for the language $\\Sigma^*P$. By exploiting this property\n",
      "and the method presented by Cantone et al. (2010), we obtain a bit-parallel\n",
      "encoding of the swap automaton which takes $O(\\sigma^2\\ceil{k/w})$ space and\n",
      "allows one to simulate the automaton on a string of length $n$ in time\n",
      "$O(n\\ceil{k/w})$, where $\\ceil{m/\\sigma}\\le k\\le m$.\n",
      "\n",
      "\n",
      " Concepts: automaton, string, swapped, swap, length\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the osigma2ceilkw space used to simulate?\n",
      "  2. What is the derived p series local swaps given?\n",
      "  3. What is the p string derived p series local swaps?\n",
      "================================================================================\n",
      "\n",
      " Abstract 228722:\n",
      "  We show that Monotone 3-Sat remains NP-complete if (i) each clause contains\n",
      "exactly three distinct variables, (ii) each clause is unique, i.e., there are\n",
      "no duplicates of the same clause, and (iii), amongst the clauses, each variable\n",
      "appears unnegated exactly twice and negated exactly twice. Darmann and D\\\"ocker\n",
      "[6] recently showed that this variant of Monotone 3-Sat is either trivial or\n",
      "NP-complete. In the first part of the paper, we construct an unsatisfiable\n",
      "instance which answers one of their open questions (Challenge 1) and places the\n",
      "problem in the latter category.\n",
      "  Then, we adapt gadgets used in the construction to (1) sketch two reductions\n",
      "that establish NP-completeness in a more direct way, and (2), to show that\n",
      "$\\forall\\exists$ 3-SAT remains $\\Pi_2^P$-complete for quantified Boolean\n",
      "formulas with the following properties: (a) each clause is monotone (i.e., no\n",
      "clause contains an unnegated and a negated variable) and contains exactly three\n",
      "distinct variables, (b) each universal variable appears exactly once unnegated\n",
      "and exactly once negated, (c) each existential variable appears exactly twice\n",
      "unnegated and exactly twice negated, and (d) the number of universal and\n",
      "existential variables is equal. Furthermore, we show that the variant where (b)\n",
      "is replaced with (b') each universal variable appears exactly twice unnegated\n",
      "and exactly twice negated, and where (a), (c) and (d) are unchanged, is\n",
      "$\\Pi_2^P$-complete as well. Thereby, we improve upon two recent results by\n",
      "D\\\"ocker et al. [8] that establish $\\Pi_2^P$-completeness of these variants in\n",
      "the non-monotone setting.\n",
      "  We also discuss a special case of Monotone 3-Sat-(2,2) that corresponds to a\n",
      "variant of Not-All-Equal Sat, and we show that all such instances are\n",
      "satisfiable.\n",
      "\n",
      "\n",
      " Concepts: unnegated, negated, variable, clause, universal\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the difference between b universal variable and b universal variable?\n",
      "  2. What is the number universal existential variables equal furthermore show variant b replaced b universal variable appears exactly twice?\n",
      "  3. What does the npcomplete clause contain exactly twice negated?\n",
      "================================================================================\n",
      "\n",
      " Abstract 584252:\n",
      "  This paper revisits cluster-based retrieval that partitions the inverted\n",
      "index into multiple groups and skips the index partially at cluster and\n",
      "document levels during online inference using a learned sparse representation.\n",
      "It proposes an approximate search scheme with two parameters to control the\n",
      "rank-safeness competitiveness of pruning with segmented maximum term weights\n",
      "within each cluster. Cluster-level maximum weight segmentation allows an\n",
      "improvement in the rank score bound estimation and threshold-based pruning to\n",
      "be approximately adaptive to bound estimation tightness, resulting in better\n",
      "relevance and efficiency. The experiments with MS MARCO passage ranking and\n",
      "BEIR datasets demonstrate the usefulness of the proposed scheme with a\n",
      "comparison to the baselines. This paper presents the design of this approximate\n",
      "retrieval scheme with rank-safeness analysis, compares clustering and\n",
      "segmentation options, and reports evaluation results.\n",
      "\n",
      "\n",
      " Concepts: bound, estimation, scheme, paper, retrieval\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the improvement rank score?\n",
      "  2. What is tightness resulting better relevance efficiency experiments?\n",
      "  3. What does paper present design approximate retrieval?\n",
      "================================================================================\n",
      "\n",
      " Abstract 450526:\n",
      "  There has been a recent effort in applying differential privacy on memory\n",
      "access patterns to enhance data privacy. This is called differential\n",
      "obliviousness. Differential obliviousness is a promising direction because it\n",
      "provides a principled trade-off between performance and desired level of\n",
      "privacy. To date, it is still an open question whether differential\n",
      "obliviousness can speed up database processing with respect to full\n",
      "obliviousness. In this paper, we present the design and implementation of three\n",
      "new major database operators: selection with projection, grouping with\n",
      "aggregation, and foreign key join. We prove that they satisfy the notion of\n",
      "differential obliviousness. Our differentially oblivious operators have reduced\n",
      "cache complexity, runtime complexity, and output size compared to their\n",
      "state-of-the-art fully oblivious counterparts. We also demonstrate that our\n",
      "implementation of these differentially oblivious operators can outperform their\n",
      "state-of-the-art fully oblivious counterparts by up to $7.4\\times$.\n",
      "\n",
      "\n",
      " Concepts: oblivious, differential, obliviousness, fully, operators\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the term for a new major database operators selection grouping aggregation foreign key join?\n",
      "  2. What does the recent effort to apply to data privacy enhance data privacy?\n",
      "  3. What is the term for the principled tradeoff performance desired level privacy date still open question?\n",
      "================================================================================\n",
      "\n",
      " Abstract 573831:\n",
      "  In this work, a theorem is first proved which presents a game theoretic\n",
      "formulation of a necessary and sufficient sustainizability over a set condition\n",
      "for a general system described by ordinary differential equations (ODEs). Then,\n",
      "two additional theorems are proved for the n-species Gause-Lotka-Volterra (GLV)\n",
      "population model, establishing necessary and sufficient sustainability and\n",
      "sustainizability conditions over rectangular sets. Three case studies on the\n",
      "May-Leonard, 3-species, GLV model are then presented to illustrate the power of\n",
      "the above Theorems. In two of these case studies (2 and 3), it is shown that a\n",
      "particular instance of the 3-species, GLV model is unsustainable but\n",
      "sustainizable through allowable action.\n",
      "\n",
      "\n",
      " Concepts: glv, model, sufficient, case, studies\n",
      "\n",
      " Generated Questions:\n",
      "  1. What model was presented illustrate power theorems two case studies 2 3 shown particular instance 3species?\n",
      "  2. What model did theorems show a case study 2 3 shown particular instance 3species glv ?\n",
      "  3. What is theoretic formulation necessary?\n",
      "================================================================================\n",
      "\n",
      " Abstract 102817:\n",
      "  We propose a major revision of the format XCSP 2.1, called XCSP3, to build\n",
      "integrated representations of combinatorial constrained problems. This new\n",
      "format is able to deal with mono/multi optimization, many types of variables,\n",
      "cost functions, reification, views, annotations, variable quantification,\n",
      "distributed, probabilistic and qualitative reasoning. The new format is made\n",
      "compact, highly readable, and rather easy to parse. Interestingly, it captures\n",
      "the structure of the problem models, through the possibilities of declaring\n",
      "arrays of variables, and identifying syntactic and semantic groups of\n",
      "constraints. The number of constraints is kept under control by introducing a\n",
      "limited set of basic constraint forms, and producing almost automatically some\n",
      "of their variations through lifting, restriction, sliding, logical combination\n",
      "and relaxation mechanisms. As a result, XCSP3 encompasses practically all\n",
      "constraints that can be found in major constraint solvers developed by the CP\n",
      "community. A website, which is developed conjointly with the format, contains\n",
      "many models and series of instances. The user can make sophisticated queries\n",
      "for selecting instances from very precise criteria. The objective of XCSP3 is\n",
      "to ease the effort required to test and compare different algorithms by\n",
      "providing a common test-bed of combinatorial constrained instances.\n",
      "\n",
      "\n",
      " Concepts: format, instances, combinatorial, constrained, called\n",
      "\n",
      " Generated Questions:\n",
      "  1. What format was developed jointly?\n",
      "  2. What is the main reason for the cp community website developed conjointly format contains many models series?\n",
      "  3. What type of constrained instances are common testbed?\n",
      "================================================================================\n",
      "\n",
      " Abstract 224185:\n",
      "  One of the significant issues in the music supply chain today is the lack of\n",
      "consistent, complete and authoritative information or metadata regarding the\n",
      "creation of a given musical work. In many cases multiple entities in the music\n",
      "supply chain have each created their own version of the metadata for a musical\n",
      "work, often by manually re-entering the same information or through scraping\n",
      "data from other sites. In such cases, the effort to synchronize or to correct\n",
      "the information becomes manually laborious and error-prone. Furthermore,\n",
      "confidential information regarding the legal ownership of the musical work is\n",
      "often commingled in the same metadata, making the entire database proprietary\n",
      "and thus closed. In this paper we explore an alternative model for creation\n",
      "metadata following the open access paradigm found in other industries, such as\n",
      "in book publishing, library systems and in the automotive parts supply chain.\n",
      "The vision is to create a new music metadata layer for creation metadata that\n",
      "is open, scalable and provides an authoritative source of information that is\n",
      "available to all entities in the music supply chain globally.\n",
      "\n",
      "\n",
      " Concepts: supply, chain, music, work, metadata\n",
      "\n",
      " Generated Questions:\n",
      "  1. What chain lack consistent authoritative information metadata regarding creation given musical work many cases multiple entities music ?\n",
      "  2. What is the most important issue of music supply?\n",
      "  3. What supply chain lacks consistent complete authoritative information metadata regarding creation?\n",
      "================================================================================\n",
      "\n",
      " Abstract 432050:\n",
      "  Recent works of Roughgarden (EC'21) and Chung and Shi (SODA'23) initiate the\n",
      "study of a new decentralized mechanism design problem called transaction fee\n",
      "mechanism design (TFM). Unlike the classical mechanism design literature, in\n",
      "the decentralized environment, even the auctioneer (i.e., the miner) can be a\n",
      "strategic player, and it can even collude with a subset of the users\n",
      "facilitated by binding side contracts. Chung and Shi showed two main\n",
      "impossibility results that rule out the existence of a {\\it dream} TFM. First,\n",
      "any TFM that provides incentive compatibility for individual users and\n",
      "miner-user coalitions must always have zero miner revenue, no matter whether\n",
      "the block size is finite or infinite. Second, assuming finite block size, no\n",
      "non-trivial TFM can simultaenously provide incentive compatibility for any\n",
      "individual user, and for any miner-user coalition.\n",
      "  In this work, we explore what new models and meaningful relaxations can allow\n",
      "us to circumvent the impossibility results of Chung and Shi. Besides today's\n",
      "model that does not employ cryptography, we introduce a new MPC-assisted model\n",
      "where the TFM is implemented by a joint multi-party computation (MPC) protocol\n",
      "among the miners. We prove several feasibility and infeasibility results for\n",
      "achieving {\\it strict} and {\\it approximate} incentive compatibility,\n",
      "respectively, in the plain model as well as the MPC-assisted model. We show\n",
      "that while cryptography is not a panacea, it indeed allows us to overcome some\n",
      "impossibility results pertaining to the plain model, leading to non-trivial\n",
      "mechanisms with useful guarantees that are otherwise impossible in the plain\n",
      "model. Our work is also the first to characterize the mathematical landscape of\n",
      "transaction fee mechanism design under approximate incentive compatibility, as\n",
      "well as in a cryptography-assisted model.\n",
      "\n",
      "\n",
      " Concepts: incentive, compatibility, model, design, mechanism\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the approximate compatibility of a mineruser coalition?\n",
      "  2. What is the primary incentive for a mineruser coalition?\n",
      "  3. What model does tfm implement?\n",
      "================================================================================\n",
      "\n",
      " Abstract 572882:\n",
      "  This article describes the 2023 IEEE Low-Power Computer Vision Challenge\n",
      "(LPCVC). Since 2015, LPCVC has been an international competition devoted to\n",
      "tackling the challenge of computer vision (CV) on edge devices. Most CV\n",
      "researchers focus on improving accuracy, at the expense of ever-growing sizes\n",
      "of machine models. LPCVC balances accuracy with resource requirements. Winners\n",
      "must achieve high accuracy with short execution time when their CV solutions\n",
      "run on an embedded device, such as Raspberry PI or Nvidia Jetson Nano. The\n",
      "vision problem for 2023 LPCVC is segmentation of images acquired by Unmanned\n",
      "Aerial Vehicles (UAVs, also called drones) after disasters. The 2023 LPCVC\n",
      "attracted 60 international teams that submitted 676 solutions during the\n",
      "submission window of one month. This article explains the setup of the\n",
      "competition and highlights the winners' methods that improve accuracy and\n",
      "shorten execution time.\n",
      "\n",
      "\n",
      " Concepts: lpcvc, vision, accuracy, computer, execution\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the name of the international competition devoted to computer vision cv edge devices?\n",
      "  2. What is the challenge computer lpcvc international competition devoted to?\n",
      "  3. What is the goal of a competition?\n",
      "================================================================================\n",
      "\n",
      " Abstract 717230:\n",
      "  Spartan Spatial Random Fields (SSRFs) are generalized Gibbs random fields,\n",
      "equipped with a coarse-graining kernel that acts as a low-pass filter for the\n",
      "fluctuations. SSRFs are defined by means of physically motivated spatial\n",
      "interactions and a small set of free parameters (interaction couplings). This\n",
      "paper focuses on the FGC-SSRF model, which is defined on the Euclidean space\n",
      "$\\mathbb{R}^{d}$ by means of interactions proportional to the squares of the\n",
      "field realizations, as well as their gradient and curvature. The permissibility\n",
      "criteria of FGC-SSRFs are extended by considering the impact of a\n",
      "finite-bandwidth kernel. It is proved that the FGC-SSRFs are almost surely\n",
      "differentiable in the case of finite bandwidth. Asymptotic explicit expressions\n",
      "for the Spartan covariance function are derived for $d=1$ and $d=3$; both known\n",
      "and new covariance functions are obtained depending on the value of the\n",
      "FGC-SSRF shape parameter. Nonlinear dependence of the covariance integral scale\n",
      "on the FGC-SSRF characteristic length is established, and it is shown that the\n",
      "relation becomes linear asymptotically. The results presented in this paper are\n",
      "useful in random field parameter inference, as well as in spatial interpolation\n",
      "of irregularly-spaced samples.\n",
      "\n",
      "\n",
      " Concepts: random, covariance, spatial, fgcssrf, spartan\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of field parameter inference well spatial interpolation irregularlyspaced samples?\n",
      "  2. What is the name of the function that derived from fgcssrf shape parameter nonlinear dependence?\n",
      "  3. What is the interpolation irregularlyspaced sample?\n",
      "================================================================================\n",
      "\n",
      " Abstract 451007:\n",
      "  Score-based generative models are shown to achieve remarkable empirical\n",
      "performances in various applications such as image generation and audio\n",
      "synthesis. However, a theoretical understanding of score-based diffusion models\n",
      "is still incomplete. Recently, Song et al. showed that the training objective\n",
      "of score-based generative models is equivalent to minimizing the\n",
      "Kullback-Leibler divergence of the generated distribution from the data\n",
      "distribution. In this work, we show that score-based models also minimize the\n",
      "Wasserstein distance between them under suitable assumptions on the model.\n",
      "Specifically, we prove that the Wasserstein distance is upper bounded by the\n",
      "square root of the objective function up to multiplicative constants and a\n",
      "fixed constant offset. Our proof is based on a novel application of the theory\n",
      "of optimal transport, which can be of independent interest to the society. Our\n",
      "numerical experiments support our findings. By analyzing our upper bounds, we\n",
      "provide a few techniques to obtain tighter upper bounds.\n",
      "\n",
      "\n",
      " Concepts: scorebased, generative, models, upper, wasserstein\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the training objective of song et al?\n",
      "  2. What type of model did song et al show training objective scorebased?\n",
      "  3. What did scorebased generative models demonstrate achieve remarkable empirical performances?\n",
      "================================================================================\n",
      "\n",
      " Abstract 419535:\n",
      "  Online continual learning (online CL) studies the problem of learning\n",
      "sequential tasks from an online data stream without task boundaries, aiming to\n",
      "adapt to new data while alleviating catastrophic forgetting on the past tasks.\n",
      "This paper proposes a framework Contrastive Vision Transformer (CVT), which\n",
      "designs a focal contrastive learning strategy based on a transformer\n",
      "architecture, to achieve a better stability-plasticity trade-off for online CL.\n",
      "Specifically, we design a new external attention mechanism for online CL that\n",
      "implicitly captures previous tasks' information. Besides, CVT contains\n",
      "learnable focuses for each class, which could accumulate the knowledge of\n",
      "previous classes to alleviate forgetting. Based on the learnable focuses, we\n",
      "design a focal contrastive loss to rebalance contrastive learning between new\n",
      "and past classes and consolidate previously learned representations. Moreover,\n",
      "CVT contains a dual-classifier structure for decoupling learning current\n",
      "classes and balancing all observed classes. The extensive experimental results\n",
      "show that our approach achieves state-of-the-art performance with even fewer\n",
      "parameters on online CL benchmarks and effectively alleviates the catastrophic\n",
      "forgetting.\n",
      "\n",
      "\n",
      " Concepts: online, contrastive, learning, classes, forgetting\n",
      "\n",
      " Generated Questions:\n",
      "  1. What online data stream without task boundaries does cl specifically design new external attention mechanism?\n",
      "  2. What is the framework for learning new past classes?\n",
      "  3. What is the focus of cvt?\n",
      "================================================================================\n",
      "\n",
      " Abstract 446400:\n",
      "  In recent years, there has been a wide interest in designing deep neural\n",
      "network-based models that automate downstream software engineering tasks on\n",
      "source code, such as code document generation, code search, and program repair.\n",
      "Although the main objective of these studies is to improve the effectiveness of\n",
      "the downstream task, many studies only attempt to employ the next best neural\n",
      "network model, without a proper in-depth analysis of why a particular solution\n",
      "works or does not, on particular tasks or scenarios. In this paper, using an\n",
      "example eXplainable AI (XAI) method (attention mechanism), we study two recent\n",
      "large language models (LLMs) for code (CodeBERT and GraphCodeBERT) on a set of\n",
      "software engineering downstream tasks: code document generation (CDG), code\n",
      "refinement (CR), and code translation (CT). Through quantitative and\n",
      "qualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the\n",
      "highest attention on, in terms of source code token types), on these tasks. We\n",
      "also show some of the common patterns when the model does not work as expected\n",
      "(performs poorly even on easy problems) and suggest recommendations that may\n",
      "alleviate the observed challenges.\n",
      "\n",
      "\n",
      " Concepts: code, tasks, downstream, document, studies\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the main objective of qualitative studies?\n",
      "  2. What is the main objective of studies that improve effectiveness downstream task?\n",
      "  3. What is the main objective of deep neural networkbased models?\n",
      "================================================================================\n",
      "\n",
      " Abstract 398548:\n",
      "  The new concept of semi-integrated-sensing-and-communication (Semi-ISaC) is\n",
      "proposed for next-generation cellular networks. Compared to the\n",
      "state-of-the-art, where the total bandwidth is used for integrated sensing and\n",
      "communication (ISaC), the proposed Semi-ISaC framework provides more freedom as\n",
      "it allows that a portion of the bandwidth is exclusively used for either\n",
      "wireless communication or radar detection, while the rest is for ISaC\n",
      "transmission. To enhance the bandwidth efficiency (BE), we investigate the\n",
      "evolution of Semi-ISaC networks from orthogonal multiple access (OMA) to\n",
      "non-orthogonal multiple access (NOMA). First, we evaluate the performance of an\n",
      "OMA-based Semi-ISaC network. As for the communication signals, we investigate\n",
      "both the outage probability (OP) and the ergodic rate. As for the radar echoes,\n",
      "we characterize the ergodic radar estimation information rate (REIR). Then, we\n",
      "investigate the performance of a NOMA-based Semi-ISaC network, including the OP\n",
      "and the ergodic rate for communication signals and the ergodic REIR for radar\n",
      "echoes. The diversity gains of OP and the high signal-to-noise ratio (SNR)\n",
      "slopes of the ergodic REIR are also evaluated as insights. The analytical\n",
      "results indicate that: 1) Under a two-user NOMA-based Semi-ISaC scenario, the\n",
      "diversity order of the near-user is equal to the coefficient of the Nakagami-m\n",
      "fading channels (m), while that of the far-user is zero; and 2) The high-SNR\n",
      "slope for the ergodic REIR is based on the ratio of the radar signal's duty\n",
      "cycle to the pulse duration. Our simulation results show that: 1) Semi-ISaC has\n",
      "better channel capacity than the conventional ISaC; and 2) The NOMA-based\n",
      "Semi-ISaC has better channel capacity than the OMA-based Semi-ISaC.\n",
      "\n",
      "\n",
      " Concepts: semiisac, ergodic, radar, reir, communication\n",
      "\n",
      " Generated Questions:\n",
      "  1. What isac framework provides freedom?\n",
      "  2. What is reir radar echoes characterize?\n",
      "  3. What isac transmission is reir?\n",
      "================================================================================\n",
      "\n",
      " Abstract 630504:\n",
      "  This paper examines two different variants of the Ludo game, involving\n",
      "multiple dice and a fixed number of total turns. Within each variant, multiple\n",
      "game lengths (total no. of turns) are considered. To compare the two variants,\n",
      "a set of intuitive, rule-based strategies is designed, representing different\n",
      "broad methods of strategic play. Game play is simulated between bots (automated\n",
      "software applications executing repetitive tasks over a network) following\n",
      "these strategies. The expected results are computed using certain game\n",
      "theoretic and probabilistic explanations, helping to understand the performance\n",
      "of the different strategies. The different strategies are further analyzed\n",
      "using win percentage in a large number of simulations, and Nash Equilibrium\n",
      "strategies are computed for both variants for a varying number of total turns.\n",
      "The Nash Equilibrium strategies across different game lengths are compared. A\n",
      "clear distinction between performances of strategies is observed, with more\n",
      "sophisticated strategies beating the naive one. A gradual shift in optimal\n",
      "strategy profiles is observed with changing game length, and certain\n",
      "sophisticated strategies even confound each other's performance while playing\n",
      "against each other.\n",
      "\n",
      "\n",
      " Concepts: strategies, game, total, turns, number\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is naive one gradual shift optimal strategy profiles?\n",
      "  2. What is theoretic probabilistic explanations for how to understand performance different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different strategies different\n",
      "  3. What is the total number of turns considered?\n",
      "================================================================================\n",
      "\n",
      " Abstract 195310:\n",
      "  We present a system for learning full-body neural avatars, i.e. deep networks\n",
      "that produce full-body renderings of a person for varying body pose and camera\n",
      "position. Our system takes the middle path between the classical graphics\n",
      "pipeline and the recent deep learning approaches that generate images of humans\n",
      "using image-to-image translation. In particular, our system estimates an\n",
      "explicit two-dimensional texture map of the model surface. At the same time, it\n",
      "abstains from explicit shape modeling in 3D. Instead, at test time, the system\n",
      "uses a fully-convolutional network to directly map the configuration of body\n",
      "feature points w.r.t. the camera to the 2D texture coordinates of individual\n",
      "pixels in the image frame. We show that such a system is capable of learning to\n",
      "generate realistic renderings while being trained on videos annotated with 3D\n",
      "poses and foreground masks. We also demonstrate that maintaining an explicit\n",
      "texture representation helps our system to achieve better generalization\n",
      "compared to systems that use direct image-to-image translation.\n",
      "\n",
      "\n",
      " Concepts: system, learning, explicit, texture, imagetoimage\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does the use of direct imagetoimage translation help?\n",
      "  2. What is the present system capable of?\n",
      "  3. What kind of texture representation helps system achieve better generalization compared systems use direct imagetoimage translation?\n",
      "================================================================================\n",
      "\n",
      " Abstract 307187:\n",
      "  The problem of online prediction with sequential side information under\n",
      "logarithmic loss is studied, and general upper and lower bounds on the minimax\n",
      "regret incurred by the predictor is established. The upper bounds on the\n",
      "minimax regret are obtained by providing and analyzing a probability assignment\n",
      "inspired by mixture probability assignments in universal compression, and the\n",
      "lower bounds are obtained by way of a redundancy-capacity theorem. The tight\n",
      "characterization of the regret is provided in some special settings.\n",
      "\n",
      "\n",
      " Concepts: bounds, minimax, regret, lower, probability\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the term for the term \"minimax regret\"?\n",
      "  2. What was the most common regret obtained?\n",
      "  3. What was theorem tight characterization?\n",
      "================================================================================\n",
      "\n",
      " Abstract 709958:\n",
      "  The concept of parameter setting is a crucial and significant process in\n",
      "metaheuristics since it can majorly impact their performance. It is a highly\n",
      "complex and challenging procedure since it requires a deep understanding of the\n",
      "optimization algorithm and the optimization problem at hand. In recent years,\n",
      "the upcoming rise of autonomous decision systems has attracted ongoing\n",
      "scientific interest in this direction, utilizing a considerable number of\n",
      "parameter-tuning methods. There are two types of methods: offline and online.\n",
      "Online methods usually excel in complex real-world problems, as they can offer\n",
      "dynamic parameter control throughout the execution of the algorithm. The\n",
      "present work proposes a general-purpose online parameter-tuning method called\n",
      "Cluster-Based Parameter Adaptation (CPA) for population-based metaheuristics.\n",
      "The main idea lies in the identification of promising areas within the\n",
      "parameter search space and in the generation of new parameters around these\n",
      "areas. The method's validity has been demonstrated using the differential\n",
      "evolution algorithm and verified in established test suites of low- and\n",
      "high-dimensional problems. The obtained results are statistically analyzed and\n",
      "compared with state-of-the-art algorithms, including advanced auto-tuning\n",
      "approaches. The analysis reveals the promising solid CPA's performance as well\n",
      "as its robustness under a variety of benchmark problems and dimensions.\n",
      "\n",
      "\n",
      " Concepts: methods, parameter, online, parametertuning, algorithm\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of methods excel complex realworld problems offer dynamic parameter control throughout execution algorithm present work proposes generalpurpose online parametertuning method called clusterbased parameter adaptation cpa populationbased metaheuristics main idea lies identification promising areas within parameter search space generation new parameters around areas?\n",
      "  2. What is the main idea of a complex realworld problem?\n",
      "  3. What type of method is clusterbased parameter adaptation cpa populationbased metaheuristics main idea lies identification promising areas within parameter search space generation new parameters around areas methods validity demonstrated using differential evolution algorithm verified established test suites?\n",
      "================================================================================\n",
      "\n",
      " Abstract 430430:\n",
      "  A Las Vegas randomized algorithm is given to compute the Hermite normal form\n",
      "of a nonsingular integer matrix $A$ of dimension $n$. The algorithm uses\n",
      "quadratic integer multiplication and cubic matrix multiplication and has\n",
      "running time bounded by $O(n^3 (\\log n + \\log ||A||)^2(\\log n)^2)$ bit\n",
      "operations, where $||A||= \\max_{ij} |A_{ij}|$ denotes the largest entry of $A$\n",
      "in absolute value. A variant of the algorithm that uses pseudo-linear integer\n",
      "multiplication is given that has running time $(n^3 \\log ||A||)^{1+o(1)}$ bit\n",
      "operations, where the exponent $\"+o(1)\"$ captures additional factors $c_1 (\\log\n",
      "n)^{c_2} (\\log \\log ||A||)^{c_3}$ for positive real constants $c_1,c_2,c_3$.\n",
      "\n",
      "\n",
      " Concepts: log, bit, algorithm, integer, multiplication\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the largest entry absolute value variant algorithm uses pseudolinear integer multiplication given running time?\n",
      "  2. What is the largest entry absolute value variant algorithm used?\n",
      "  3. What uses quadratic integer multiplication cubic matrix multiplication running time bounded on3 log n log a2log n2 bit operations?\n",
      "================================================================================\n",
      "\n",
      " Abstract 603061:\n",
      "  We formulate and solve an optimal control problem with cooperative,\n",
      "mean-field coupled linear-quadratic subsystems and additional risk-aware costs\n",
      "depending on the covariance and skew of the disturbance. This problem\n",
      "quantifies the variability of the subsystem state energy rather than merely its\n",
      "expectation. In contrast to related work, we develop an alternative approach\n",
      "that illuminates a family of matrices with many analytical properties, which\n",
      "are useful for effectively extracting the mean-field coupled solution from a\n",
      "standard LQR solution.\n",
      "\n",
      "\n",
      " Concepts: meanfield, coupled, formulate, problem, solution\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the main component of a standard lqr solution?\n",
      "  2. What type of solution is standard lqr solution?\n",
      "  3. What is the purpose of a meanfield coupled linearquadratic subsystems?\n",
      "================================================================================\n",
      "\n",
      " Abstract 685952:\n",
      "  Due to their performance and simplicity, rigid body simulators are often used\n",
      "in applications where the objects of interest can considered very stiff.\n",
      "However, no material has infinite stiffness, which means there are potentially\n",
      "cases where the non-zero compliance of the seemingly rigid object can cause a\n",
      "significant difference between its trajectories when simulated in a rigid body\n",
      "or deformable simulator.\n",
      "  Similarly to how adversarial attacks are developed against image classifiers,\n",
      "we propose an adversarial attack against rigid body simulators. In this\n",
      "adversarial attack, we solve an optimization problem to construct perceptually\n",
      "rigid adversarial objects that have the same collision geometry and moments of\n",
      "mass to a reference object, so that they behave identically in rigid body\n",
      "simulations but maximally different in more accurate deformable simulations. We\n",
      "demonstrate the validity of our method by comparing simulations of several\n",
      "examples in commercially available simulators.\n",
      "\n",
      "\n",
      " Concepts: body, rigid, adversarial, simulators, simulations\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of simulators are used for simulations?\n",
      "  2. What is the result of a body simulation?\n",
      "  3. What type of attack solve optimization problem construct?\n",
      "================================================================================\n",
      "\n",
      " Abstract 539395:\n",
      "  The widespread deployment of inverter-based resources (IBRs) renders\n",
      "distribution systems susceptible to transmission-level faults. This paper\n",
      "presents a comprehensive analysis of the impact of transmission-level faults on\n",
      "3-phase and 1-phase distribution IBR operation. To evaluate distributed IBR\n",
      "tripping across various phases and locations on a distribution feeder, we\n",
      "conduct simulations of both symmetrical and unsymmetrical transmission faults\n",
      "at progressively greater electrical distances on a real-time transmission and\n",
      "distribution (T&D) co-simulation platform. The IBR power-to-load ratios (PLRs)\n",
      "at 50%, 100%, and 300% are considered to emulate low, medium, and high IBR\n",
      "conditions. Our results indicate that, while 1-phase and 2-phase faults\n",
      "typically trigger fewer IBR trips when compared to 3-phase faults, a\n",
      "significant power imbalance arises from the tripping of 1-phase IBRs on the\n",
      "affected phases. The imbalance can result in significant power quality problems\n",
      "and unintended equipment tripping. It may be necessary to design\n",
      "fault-ride-through mechanisms specifically tailored to 1-phase IBRs to help\n",
      "mitigate the power imbalances caused by unbalanced faults.\n",
      "\n",
      "\n",
      " Concepts: faults, power, distribution, ibr, tripping\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the most common cause of a symmetrical unsymmetrical transmission?\n",
      "  2. What is the cause of unbalanced faults?\n",
      "  3. What is the primary component of a ibr operation?\n",
      "================================================================================\n",
      "\n",
      " Abstract 684890:\n",
      "  Intimate Partner Infiltration (IPI)--a type of Intimate Partner Violence\n",
      "(IPV) that typically requires physical access to a victim's device--is a\n",
      "pervasive concern in the United States, often manifesting through digital\n",
      "surveillance, control, and monitoring. Unlike conventional cyberattacks, IPI\n",
      "perpetrators leverage close proximity and personal knowledge to circumvent\n",
      "standard protections, underscoring the need for targeted interventions. While\n",
      "security clinics and other human-centered approaches effectively tailor\n",
      "solutions for survivors, their scalability remains constrained by resource\n",
      "limitations and the need for specialized counseling. In this paper, we present\n",
      "AID, an Automated IPI Detection system that continuously monitors for\n",
      "unauthorized access and suspicious behaviors on smartphones. AID employs a\n",
      "two-stage architecture to process multimodal signals stealthily and preserve\n",
      "user privacy. A brief calibration phase upon installation enables AID to adapt\n",
      "to each user's behavioral patterns, achieving high accuracy with minimal false\n",
      "alarms. Our 27-participant user study demonstrates that AID achieves highly\n",
      "accurate detection of non-owner access and fine-grained IPI-related activities,\n",
      "attaining an end-to-end top-3 F1 score of 0.981 with a false positive rate of\n",
      "4%. These findings suggest that AID can serve as a forensic tool within\n",
      "security clinics, scaling their ability to identify IPI tactics and deliver\n",
      "personalized, far-reaching support to survivors.\n",
      "\n",
      "\n",
      " Concepts: aid, access, ipi, intimate, partner\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does a twostage architecture process do?\n",
      "  2. What type of deviceis pervasive concern is ipv typically requires physical?\n",
      "  3. What type of behavior does a person use to monitor unauthorized access?\n",
      "================================================================================\n",
      "\n",
      " Abstract 238532:\n",
      "  We present a full-program induction technique for proving (a sub-class of)\n",
      "quantified as well as quantifier-free properties of programs manipulating\n",
      "arrays of parametric size N. Instead of inducting over individual loops, our\n",
      "technique inducts over the entire program (possibly containing multiple loops)\n",
      "directly via the program parameter N. Significantly, this does not require\n",
      "generation or use of loop-specific invariants. We have developed a prototype\n",
      "tool Vajra to assess the efficacy of our technique. We demonstrate the\n",
      "performance of Vajra vis-a-vis several state-of-the-art tools on a set of array\n",
      "manipulating benchmarks.\n",
      "\n",
      "\n",
      " Concepts: technique, present, benchmarks, manipulating, loops\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does vajra assess efficacy?\n",
      "  2. What is the fullprogram induction technique?\n",
      "  3. What is the array manipulating?\n",
      "================================================================================\n",
      "\n",
      " Abstract 471485:\n",
      "  This paper proposes a methodology for discovering meaningful properties in\n",
      "data by exploring the latent space of unsupervised deep generative models. We\n",
      "combine manipulation of individual latent variables to extreme values with\n",
      "methods inspired by causal inference into an approach we call causal\n",
      "disentanglement with extreme values (CDEV) and show that this method yields\n",
      "insights for model interpretability. With this, we can test for what properties\n",
      "of unknown data the model encodes as meaningful, using it to glean insight into\n",
      "the communication system of sperm whales (Physeter macrocephalus), one of the\n",
      "most intriguing and understudied animal communication systems. The network\n",
      "architecture used has been shown to learn meaningful representations of speech;\n",
      "here, it is used as a learning mechanism to decipher the properties of another\n",
      "vocal communication system in which case we have no ground truth. The proposed\n",
      "methodology suggests that sperm whales encode information using the number of\n",
      "clicks in a sequence, the regularity of their timing, and audio properties such\n",
      "as the spectral mean and the acoustic regularity of the sequences. Some of\n",
      "these findings are consistent with existing hypotheses, while others are\n",
      "proposed for the first time. We also argue that our models uncover rules that\n",
      "govern the structure of units in the communication system and apply them while\n",
      "generating innovative data not shown during training. This paper suggests that\n",
      "an interpretation of the outputs of deep neural networks with causal inference\n",
      "methodology can be a viable strategy for approaching data about which little is\n",
      "known and presents another case of how deep learning can limit the hypothesis\n",
      "space. Finally, the proposed approach can be extended to other architectures\n",
      "and datasets.\n",
      "\n",
      "\n",
      " Concepts: communication, system, causal, properties, data\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the system case ground truth?\n",
      "  2. What is the case ground truth?\n",
      "  3. What is the inference methodology inspired by?\n",
      "================================================================================\n",
      "\n",
      " Abstract 548674:\n",
      "  Network Pruning is a promising way to address the huge computing resource\n",
      "demands of the deployment and inference of Large Language Models (LLMs).\n",
      "Retraining-free is important for LLMs' pruning methods. However, almost all of\n",
      "the existing retraining-free pruning approaches for LLMs focus on unstructured\n",
      "pruning, which requires specific hardware support for acceleration. In this\n",
      "paper, we propose a novel retraining-free structured pruning framework for\n",
      "LLMs, named FLAP (FLuctuation-based Adaptive Structured Pruning). It is\n",
      "hardware-friendly by effectively reducing storage and enhancing inference\n",
      "speed. For effective structured pruning of LLMs, we highlight three critical\n",
      "elements that demand the utmost attention: formulating structured importance\n",
      "metrics, adaptively searching the global compressed model, and implementing\n",
      "compensation mechanisms to mitigate performance loss. First, FLAP determines\n",
      "whether the output feature map is easily recoverable when a column of weight is\n",
      "removed, based on the fluctuation pruning metric. Then it standardizes the\n",
      "importance scores to adaptively determine the global compressed model\n",
      "structure. At last, FLAP adds additional bias terms to recover the output\n",
      "feature maps using the baseline values. We thoroughly evaluate our approach on\n",
      "a variety of language benchmarks. Without any retraining, our method\n",
      "significantly outperforms the state-of-the-art methods, including LLM-Pruner\n",
      "and the extension of Wanda in structured pruning. The code is released at\n",
      "https://github.com/CASIA-IVA-Lab/FLAP.\n",
      "\n",
      "\n",
      " Concepts: pruning, structured, llms, retrainingfree, flap\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the most important method to network?\n",
      "  2. What type of pruning framework does llmpruner extension wanda use?\n",
      "  3. What is the name of the type of pruning that requires specific hardware support acceleration paper?\n",
      "================================================================================\n",
      "\n",
      " Abstract 679917:\n",
      "  The rapid development of Deepfake technology has enabled the generation of\n",
      "highly realistic manipulated videos, posing severe social and ethical\n",
      "challenges. Existing Deepfake detection methods primarily focused on either\n",
      "spatial or temporal inconsistencies, often neglecting the interplay between the\n",
      "two or suffering from interference caused by natural facial motions. To address\n",
      "these challenges, we propose the global context consistency flow (GC-ConsFlow),\n",
      "a novel dual-stream framework that effectively integrates spatial and temporal\n",
      "features for robust Deepfake detection. The global grouped context aggregation\n",
      "module (GGCA), integrated into the global context-aware frame flow stream\n",
      "(GCAF), enhances spatial feature extraction by aggregating grouped global\n",
      "context information, enabling the detection of subtle, spatial artifacts within\n",
      "frames. The flow-gradient temporal consistency stream (FGTC), rather than\n",
      "directly modeling the residuals, it is used to improve the robustness of\n",
      "temporal feature extraction against the inconsistency introduced by unnatural\n",
      "facial motion using optical flow residuals and gradient-based features. By\n",
      "combining these two streams, GC-ConsFlow demonstrates the effectiveness and\n",
      "robustness in capturing complementary spatiotemporal forgery traces. Extensive\n",
      "experiments show that GC-ConsFlow outperforms existing state-of-the-art methods\n",
      "in detecting Deepfake videos under various compression scenarios.\n",
      "\n",
      "\n",
      " Concepts: temporal, deepfake, spatial, global, detection\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the purpose of gcconsflow?\n",
      "  2. What type of detection method is primarily focused on spatial temporal inconsistencies?\n",
      "  3. What is the purpose of deepfake detection?\n",
      "================================================================================\n",
      "\n",
      " Abstract 18958:\n",
      "  Distributed storage infrastructures require the use of data redundancy to\n",
      "achieve high data reliability. Unfortunately, the use of redundancy introduces\n",
      "storage and communication overheads, which can either reduce the overall\n",
      "storage capacity of the system or increase its costs. To mitigate the storage\n",
      "and communication overhead, different redundancy schemes have been proposed.\n",
      "However, due to the great variety of underlaying storage infrastructures and\n",
      "the different application needs, optimizing these redundancy schemes for each\n",
      "storage infrastructure is cumbersome. The lack of rules to determine the\n",
      "optimal level of redundancy for each storage configuration leads developers in\n",
      "industry to often choose simpler redundancy schemes, which are usually not the\n",
      "optimal ones. In this paper we analyze the cost of different redundancy schemes\n",
      "and derive a set of rules to determine which redundancy scheme minimizes the\n",
      "storage and the communication costs for a given system configuration.\n",
      "Additionally, we use simulation to show that theoretically-optimal schemes may\n",
      "not be viable in a realistic setting where nodes can go off-line and repairs\n",
      "may be delayed. In these cases, we identify which are the trade-offs between\n",
      "the storage and communication overheads of the redundancy scheme and its data\n",
      "reliability.\n",
      "\n",
      "\n",
      " Concepts: redundancy, storage, communication, schemes, data\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the most common type of storage infrastructure?\n",
      "  2. redundancy schemes which reduces overall a redundancy scheme?\n",
      "  3. What overheads may redundancy scheme reduce storage?\n",
      "================================================================================\n",
      "\n",
      " Abstract 491535:\n",
      "  This study explores a new methodology for machine learning classification\n",
      "tasks in 2-dimensional visualization space (2-D ML) using Visual knowledge\n",
      "Discovery in lossless General Line Coordinates. It is shown that this is a full\n",
      "machine learning approach that does not require processing n-dimensional data\n",
      "in an abstract n-dimensional space. It enables discovering n-D patterns in 2-D\n",
      "space without loss of n-D information using graph representations of n-D data\n",
      "in 2-D. Specifically, this study shows that it can be done with static and\n",
      "dynamic In-line Based Coordinates in different modifications, which are a\n",
      "category of General Line Coordinates. Based on these inline coordinates,\n",
      "classification and regression methods were developed. The viability of the\n",
      "strategy was shown by two case studies based on benchmark datasets (Wisconsin\n",
      "Breast Cancer and Page Block Classification datasets). The characteristics of\n",
      "page block classification data led to the development of an algorithm for\n",
      "imbalanced high-resolution data with multiple classes, which exploits the\n",
      "decision trees as a model design facilitator producing a model, which is more\n",
      "general than a decision tree. This work accelerates the ongoing consolidation\n",
      "of an emerging field of full 2-D machine learning and its methodology. Within\n",
      "this methodology the end users can discover models and justify them as\n",
      "self-service. Providing interpretable ML models is another benefit of this\n",
      "approach.\n",
      "\n",
      "\n",
      " Concepts: machine, learning, line, block, classification\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the new methodology for learning?\n",
      "  2. What approach requires processing ndimensional data abstract ndimensional space?\n",
      "  3. What coordinates are used to find nd patterns?\n",
      "================================================================================\n",
      "\n",
      " Abstract 572595:\n",
      "  In this paper, we propose a new image-based visual place recognition (VPR)\n",
      "framework by exploiting the structural cues in bird's-eye view (BEV) from a\n",
      "single monocular camera. The motivation arises from two key observations about\n",
      "place recognition methods based on both appearance and structure: 1) For the\n",
      "methods relying on LiDAR sensors, the integration of LiDAR in robotic systems\n",
      "has led to increased expenses, while the alignment of data between different\n",
      "sensors is also a major challenge. 2) Other image-/camera-based methods,\n",
      "involving integrating RGB images and their derived variants (eg, pseudo depth\n",
      "images, pseudo 3D point clouds), exhibit several limitations, such as the\n",
      "failure to effectively exploit the explicit spatial relationships between\n",
      "different objects. To tackle the above issues, we design a new BEV-enhanced VPR\n",
      "framework, namely BEV$^2$PR, generating a composite descriptor with both visual\n",
      "cues and spatial awareness based on a single camera. The key points lie in: 1)\n",
      "We use BEV features as an explicit source of structural knowledge in\n",
      "constructing global features. 2) The lower layers of the pre-trained backbone\n",
      "from BEV generation are shared for visual and structural streams in VPR,\n",
      "facilitating the learning of fine-grained local features in the visual stream.\n",
      "3) The complementary visual and structural features can jointly enhance VPR\n",
      "performance. Our BEV$^2$PR framework enables consistent performance\n",
      "improvements over several popular aggregation modules for RGB global features.\n",
      "The experiments on our collected VPR-NuScenes dataset demonstrate an absolute\n",
      "gain of 2.47% on Recall@1 for the strong Conv-AP baseline to achieve the best\n",
      "performance in our setting, and notably, a 18.06% gain on the hard set. The\n",
      "code and dataset will be available at https://github.com/FudongGe/BEV2PR.\n",
      "\n",
      "\n",
      " Concepts: visual, features, vpr, structural, framework\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the name of the structure that enables learning finegrained local features?\n",
      "  2. What does bev aggregation modules rgb global enables consistent performance improvements?\n",
      "  3. What framework is bev2pr generating composite descriptor visual cues?\n",
      "================================================================================\n",
      "\n",
      " Abstract 429429:\n",
      "  In this paper, we advocate for two stages in a neural network's decision\n",
      "making process. The first is the existing feed-forward inference framework\n",
      "where patterns in given data are sensed and associated with previously learned\n",
      "patterns. The second stage is a slower reflection stage where we ask the\n",
      "network to reflect on its feed-forward decision by considering and evaluating\n",
      "all available choices. Together, we term the two stages as introspective\n",
      "learning. We use gradients of trained neural networks as a measurement of this\n",
      "reflection. A simple three-layered Multi Layer Perceptron is used as the second\n",
      "stage that predicts based on all extracted gradient features. We perceptually\n",
      "visualize the post-hoc explanations from both stages to provide a visual\n",
      "grounding to introspection. For the application of recognition, we show that an\n",
      "introspective network is 4% more robust and 42% less prone to calibration\n",
      "errors when generalizing to noisy data. We also illustrate the value of\n",
      "introspective networks in downstream tasks that require generalizability and\n",
      "calibration including active learning, out-of-distribution detection, and\n",
      "uncertainty estimation. Finally, we ground the proposed machine introspection\n",
      "to human introspection for the application of image quality assessment.\n",
      "\n",
      "\n",
      " Concepts: introspective, introspection, networks, neural, application\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of network is it?\n",
      "  2. What is the final grounding of a proposed machine?\n",
      "  3. What is the process of evaluating available choices together term two stages introspective learning use gradients trained neural ?\n",
      "================================================================================\n",
      "\n",
      " Abstract 378291:\n",
      "  Lead pipe remediation budgets are limited and ought to maximize public health\n",
      "impact. This goal implies a non-trivial optimization problem; lead service\n",
      "lines connect water mains to individual houses, but any realistic replacement\n",
      "strategy must batch replacements at a larger scale. Additionally, planners\n",
      "typically lack a principled method for comparing the relative public health\n",
      "value of potential interventions and often plan projects based on non-health\n",
      "factors. This paper describes a simple process for estimating child health\n",
      "impact at a parcel level by cleaning and synthesizing municipal datasets that\n",
      "are commonly available but seldom joined due to data quality issues. Using\n",
      "geocoding as the core record linkage mechanism, parcel-level toxicity data can\n",
      "be combined with school enrollment records to indicate where young children and\n",
      "lead lines coexist. A harm metric of estimated exposure-years is described at\n",
      "the parcel level, which can then be aggregated to the project level and\n",
      "minimized globally by posing project selection as a 0/1 knapsack problem.\n",
      "Simplifying further for use by non-experts, the implied linear programming\n",
      "relaxation is solved intuitively with the greedy algorithm; ordering projects\n",
      "by benefit cost ratio produces a priority list which planners can then consider\n",
      "holistically alongside harder to quantify factors. A case study demonstrates\n",
      "the successful application of this framework to a small U.S. city's existing\n",
      "data to prioritize federal infrastructure funding. While this paper focuses on\n",
      "lead in drinking water, the approach readily generalizes to other sources of\n",
      "residential toxicity with disproportionate impact on children.\n",
      "\n",
      "\n",
      " Concepts: health, impact, level, lead, public\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the primary impact of lead pipe remediation budgets limited?\n",
      "  2. What is the goal of lead pipe remediation budgets limited?\n",
      "  3. What is the metric estimated exposureyears described parcel?\n",
      "================================================================================\n",
      "\n",
      " Abstract 408764:\n",
      "  In this work, we provide a fundamental unified convergence theorem used for\n",
      "deriving expected and almost sure convergence results for a series of\n",
      "stochastic optimization methods. Our unified theorem only requires to verify\n",
      "several representative conditions and is not tailored to any specific\n",
      "algorithm. As a direct application, we recover expected and almost sure\n",
      "convergence results of the stochastic gradient method (SGD) and random\n",
      "reshuffling (RR) under more general settings. Moreover, we establish new\n",
      "expected and almost sure convergence results for the stochastic proximal\n",
      "gradient method (prox-SGD) and stochastic model-based methods (SMM) for\n",
      "nonsmooth nonconvex optimization problems. These applications reveal that our\n",
      "unified theorem provides a plugin-type convergence analysis and strong\n",
      "convergence guarantees for a wide class of stochastic optimization methods.\n",
      "\n",
      "\n",
      " Concepts: convergence, results, stochastic, expected, optimization\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the result of unified theorem?\n",
      "  2. What does the unified convergence theorem require verify several representative conditions tailored specific algorithm direct application recover expected almost sure convergence?\n",
      "  3. What type of optimization methods are unified theorem used deriving expected almost sure convergence results?\n",
      "================================================================================\n",
      "\n",
      " Abstract 90148:\n",
      "  In Android, communications between apps and system services are supported by\n",
      "a transaction-based Inter-Process Communication (IPC) mechanism. Binder, as the\n",
      "cornerstone of this IPC mechanism, separates two communicating parties as\n",
      "client and server. As with any client-server model, the server should not make\n",
      "any assumption on the validity (sanity) of client-side transaction. To our\n",
      "surprise, we find this principle has frequently been overlooked in the\n",
      "implementation of Android system services. In this paper, we demonstrate the\n",
      "prevalence and severity of this vulnerability surface and try to answer why\n",
      "developers keep making this seemingly simple mistake. Specifically, we design\n",
      "and implement BinderCracker, an automatic testing framework that supports\n",
      "parameter-aware fuzzing and has identified more than 100 vulnerabilities in six\n",
      "major versions of Android, including the latest version Android 6.0,\n",
      "Marshmallow. Some of the vulnerabilities have severe security implications,\n",
      "causing privileged code execution or permanent Denial-of-Service (DoS). We\n",
      "analyzed the root causes of these vulnerabilities to find that most of them\n",
      "exist because system service developers only considered exploitations via\n",
      "public APIs. We thus highlight the deficiency of testing only on client-side\n",
      "public APIs and argue for the necessity of testing and protection on the Binder\n",
      "interface - the actual security boundary. Specifically, we discuss the\n",
      "effectiveness and practicality of potential countermeasures, such as\n",
      "precautionary testing and runtime diagnostic.\n",
      "\n",
      "\n",
      " Concepts: system, android, testing, ipc, mechanism\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the most common system for android communications apps?\n",
      "  2. What android system services supported transactionbased interprocess communication ipc mechanism binder cornerstone ipc mechanism bindercracker automatic testing framework supports parameteraware fuzzing identified 100 vulnerabilities?\n",
      "  3. What does the framework support?\n",
      "================================================================================\n",
      "\n",
      " Abstract 706025:\n",
      "  3D generation is experiencing rapid advancements, while the development of 3D\n",
      "evaluation has not kept pace. How to keep automatic evaluation equitably\n",
      "aligned with human perception has become a well-recognized challenge. Recent\n",
      "advances in the field of language and image generation have explored human\n",
      "preferences and showcased respectable fitting ability. However, the 3D domain\n",
      "still lacks such a comprehensive preference dataset over generative models. To\n",
      "mitigate this absence, we develop 3DGen-Arena, an integrated platform in a\n",
      "battle manner. Then, we carefully design diverse text and image prompts and\n",
      "leverage the arena platform to gather human preferences from both public users\n",
      "and expert annotators, resulting in a large-scale multi-dimension human\n",
      "preference dataset 3DGen-Bench. Using this dataset, we further train a\n",
      "CLIP-based scoring model, 3DGen-Score, and a MLLM-based automatic evaluator,\n",
      "3DGen-Eval. These two models innovatively unify the quality evaluation of\n",
      "text-to-3D and image-to-3D generation, and jointly form our automated\n",
      "evaluation system with their respective strengths. Extensive experiments\n",
      "demonstrate the efficacy of our scoring model in predicting human preferences,\n",
      "exhibiting a superior correlation with human ranks compared to existing\n",
      "metrics. We believe that our 3DGen-Bench dataset and automated evaluation\n",
      "system will foster a more equitable evaluation in the field of 3D generation,\n",
      "further promoting the development of 3D generative models and their downstream\n",
      "applications.\n",
      "\n",
      "\n",
      " Concepts: human, evaluation, dataset, preferences, generation\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of preferences are showcased respectable fitting ability?\n",
      "  2. What is the result of 3d generation developing rapid advancements development?\n",
      "  3. What dataset does 3dgenbench use?\n",
      "================================================================================\n",
      "\n",
      " Abstract 7422:\n",
      "  Multicast data transfers occur in many distributed systems and applications\n",
      "(e.g. IPTV, Grids, content delivery networks). Because of this, efficient\n",
      "multicast data distribution optimization techniques are required. In the first\n",
      "part of this paper we present a small diameter, bounded degree, collaborative\n",
      "peer-to-peer multicast tree architecture, which supports dynamic node arrivals\n",
      "and departures making local decisions only. The architecture is fault tolerant\n",
      "and, at low arrival and departure rates, converges towards a theoretically\n",
      "optimal structure. In the second part of the paper we consider several offline\n",
      "data distribution optimization problems, for which we present novel and\n",
      "time-efficient algorithmic solutions.\n",
      "\n",
      "\n",
      " Concepts: data, distribution, multicast, optimization, part\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the main distribution optimization technique required first part paper present small diameter bounded degree collaborative peertopeer multicast tree architecture supports dynamic node arrivals departures departures making local decisions?\n",
      "  2. What is the main reason for multicast data transfer?\n",
      "  3. What type of data transfers occur many distributed systems applications?\n",
      "================================================================================\n",
      "\n",
      " Abstract 81557:\n",
      "  Binary representation is desirable for its memory efficiency, computation\n",
      "speed and robustness. In this paper, we propose adjustable bounded rectifiers\n",
      "to learn binary representations for deep neural networks. While hard\n",
      "constraining representations across layers to be binary makes training\n",
      "unreasonably difficult, we softly encourage activations to diverge from real\n",
      "values to binary by approximating step functions. Our final representation is\n",
      "completely binary. We test our approach on MNIST, CIFAR10, and ILSVRC2012\n",
      "dataset, and systematically study the training dynamics of the binarization\n",
      "process. Our approach can binarize the last layer representation without loss\n",
      "of performance and binarize all the layers with reasonably small degradations.\n",
      "The memory space that it saves may allow more sophisticated models to be\n",
      "deployed, thus compensating the loss. To the best of our knowledge, this is the\n",
      "first work to report results on current deep network architectures using\n",
      "complete binary middle representations. Given the learned representations, we\n",
      "find that the firing or inhibition of a binary neuron is usually associated\n",
      "with a meaningful interpretation across different classes. This suggests that\n",
      "the semantic structure of a neural network may be manifested through a guided\n",
      "binarization process.\n",
      "\n",
      "\n",
      " Concepts: binary, representations, neural, binarization, process\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the term for a bounded rectifiers?\n",
      "  2. What is the purpose of binary representation?\n",
      "  3. What network may manifested guided binarization process?\n",
      "================================================================================\n",
      "\n",
      " Abstract 9361:\n",
      "  This volume contains the proceedings of the 7th Workshop on Security Issues\n",
      "in Concurrency (SecCo'09). The workshop was held in Bologna, Italy on September\n",
      "5th 2009, as a satellite workshop of CONCUR'09. The aim of the SecCo workshop\n",
      "series is to cover the gap between the security and the concurrency\n",
      "communities. More precisely, the workshop promotes the exchange of ideas,\n",
      "trying to focus on common interests and stimulating discussions on central\n",
      "research questions. In particular, we called for papers dealing with security\n",
      "issues (such as authentication, integrity, privacy, confidentiality, access\n",
      "control, denial of service, service availability, safety aspects, fault\n",
      "tolerance, trust, language-based security, probabilistic and information\n",
      "theoretic models) in emerging fields like web services, mobile ad-hoc networks,\n",
      "agent-based infrastructures, peer-to-peer systems, context-aware computing,\n",
      "global/ubiquitous/pervasive computing.\n",
      "\n",
      "\n",
      " Concepts: security, workshop, issues, concurrency, computing\n",
      "\n",
      " Generated Questions:\n",
      "  1. What issues do secco workshop cover gap?\n",
      "  2. What was bologna italy september 5th 2009 satellite ?\n",
      "  3. What is the main issue of secco09 workshop held bologna italy?\n",
      "================================================================================\n",
      "\n",
      " Abstract 347054:\n",
      "  In spin based quantum dot arrays, material or fabrication imprecisions affect\n",
      "the behaviour of the device, which must be taken into account when controlling\n",
      "it. This requires measuring the shape of specific convex polytopes. In this\n",
      "work, we present an algorithm that automatically discovers count, shape and\n",
      "size of the facets of a convex polytope from measurements. Results on simulated\n",
      "devices as well as a real 2x2 spin qubit array show that we can reliably find\n",
      "the facets of the convex polytopes, including small facets with sizes on the\n",
      "order of the measurement precision.\n",
      "\n",
      "\n",
      " Concepts: convex, spin, facets, polytopes, real\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of polytopes work present algorithm automatically discovers count shape size facets?\n",
      "  2. What is the based quantum dot array?\n",
      "  3. What size does simulated devices well real 2x2 spin qubit array show reliably find?\n",
      "================================================================================\n",
      "\n",
      " Abstract 566958:\n",
      "  A tournament is a complete directed graph. A king in a tournament is a vertex\n",
      "v such that every other vertex is reachable from v via a path of length at most\n",
      "2. It is well known that every tournament has at least one king, one of which\n",
      "is a maximum out-degree vertex. The tasks of finding a king, a maximum\n",
      "out-degree vertex and a source in a tournament has been relatively well studied\n",
      "in the context of query complexity. We study the communication complexity of\n",
      "these tasks, where the edges are partitioned between two players. The following\n",
      "are our main results for n-vertex tournaments:\n",
      "  1) The deterministic communication complexity of finding whether a source\n",
      "exists is tilde{Theta}(log^2 n).\n",
      "  2) The deterministic and randomized communication complexities of finding a\n",
      "king are Theta(n). The quantum communication complexity is\n",
      "tilde{Theta}(sqrt{n}).\n",
      "  3) The deterministic, randomized and quantum communication complexities of\n",
      "finding a maximum out-degree vertex are Theta(n log n), tilde{Theta}(n) and\n",
      "tilde{Theta}(sqrt{n}), respectively.\n",
      "  Our upper bounds hold for all partitions of edges, and the lower bounds for a\n",
      "specific partition of the edges. To show the first bullet above, we show,\n",
      "perhaps surprisingly, that finding a source in a tournament is equivalent to\n",
      "the well-studied Clique vs. Independent Set (CIS) problem on undirected graphs.\n",
      "Our bounds for finding a source then follow from known bounds on the complexity\n",
      "of the CIS problem. In view of this equivalence, we can view the task of\n",
      "finding a king in a tournament to be a natural generalization of CIS.\n",
      "  One of our lower bounds uses a fooling-set based argument, and all our other\n",
      "lower bounds follow from carefully-constructed reductions from\n",
      "Set-Disjointness.\n",
      "\n",
      "\n",
      " Concepts: finding, communication, outdegree, deterministic, king\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is a deterministic randomized quantum communication complex?\n",
      "  2. What is king thetan quantum deterministic randomized randomized randomized king thetan quantum ?\n",
      "  3. What is the maximum vertex source tournament?\n",
      "================================================================================\n",
      "\n",
      " Abstract 488082:\n",
      "  In recent years, image generation has shown a great leap in performance,\n",
      "where diffusion models play a central role. Although generating high-quality\n",
      "images, such models are mainly conditioned on textual descriptions. This begs\n",
      "the question: \"how can we adopt such models to be conditioned on other\n",
      "modalities?\". In this paper, we propose a novel method utilizing latent\n",
      "diffusion models trained for text-to-image-generation to generate images\n",
      "conditioned on audio recordings. Using a pre-trained audio encoding model, the\n",
      "proposed method encodes audio into a new token, which can be considered as an\n",
      "adaptation layer between the audio and text representations. Such a modeling\n",
      "paradigm requires a small number of trainable parameters, making the proposed\n",
      "approach appealing for lightweight optimization. Results suggest the proposed\n",
      "method is superior to the evaluated baseline methods, considering objective and\n",
      "subjective metrics. Code and samples are available at:\n",
      "https://pages.cs.huji.ac.il/adiyoss-lab/AudioToken.\n",
      "\n",
      "\n",
      " Concepts: proposed, models, audio, method, conditioned\n",
      "\n",
      " Generated Questions:\n",
      "  1. What approach is superior evaluated baseline methods?\n",
      "  2. What model does latent diffusion play central role in image generation?\n",
      "  3. What is the text representations model proposed method encodes?\n",
      "================================================================================\n",
      "\n",
      " Abstract 55377:\n",
      "  The separation dimension of a graph $G$ is the smallest natural number $k$\n",
      "for which the vertices of $G$ can be embedded in $\\mathbb{R}^k$ such that any\n",
      "pair of disjoint edges in $G$ can be separated by a hyperplane normal to one of\n",
      "the axes. Equivalently, it is the smallest possible cardinality of a family\n",
      "$\\mathcal{F}$ of permutations of the vertices of $G$ such that for any two\n",
      "disjoint edges of $G$, there exists at least one permutation in $\\mathcal{F}$\n",
      "in which all the vertices in one edge precede those in the other. In general,\n",
      "the maximum separation dimension of a graph on $n$ vertices is $\\Theta(\\log\n",
      "n)$. In this article, we focus on sparse graphs and show that the maximum\n",
      "separation dimension of a $k$-degenerate graph on $n$ vertices is $O(k \\log\\log\n",
      "n)$ and that there exists a family of $2$-degenerate graphs with separation\n",
      "dimension $\\Omega(\\log\\log n)$. We also show that the separation dimension of\n",
      "the graph $G^{1/2}$ obtained by subdividing once every edge of another graph\n",
      "$G$ is at most $(1 + o(1)) \\log\\log \\chi(G)$ where $\\chi(G)$ is the chromatic\n",
      "number of the original graph.\n",
      "\n",
      "\n",
      " Concepts: dimension, separation, graph, vertices, disjoint\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the maximum separation of graph g smallest natural number k vertices g embedded mathbbrk pair disjoint edges g separated hyperplane normal one axes?\n",
      "  2. What does thetalog show?\n",
      "  3. What is the separation dimension of kdegenerate?\n",
      "================================================================================\n",
      "\n",
      " Abstract 493211:\n",
      "  Interface problems depict many fundamental physical phenomena and widely\n",
      "apply in the engineering. However, it is challenging to develop efficient fully\n",
      "decoupled numerical methods for solving degenerate interface problems in which\n",
      "the coefficient of a PDE is discontinuous and greater than or equal to zero on\n",
      "the interface. The main motivation in this paper is to construct fully\n",
      "decoupled numerical methods for solving nonlinear degenerate interface problems\n",
      "with ``double singularities\". An efficient fully decoupled numerical method is\n",
      "proposed for nonlinear degenerate interface problems. The scheme combines deep\n",
      "neural network on the singular subdomain with finite difference method on the\n",
      "regular subdomain. The key of the new approach is to split nonlinear degenerate\n",
      "partial differential equation with interface into two independent boundary\n",
      "value problems based on deep learning. The outstanding advantages of the\n",
      "proposed schemes are that not only the convergence order of the degenerate\n",
      "interface problems on whole domain is determined by the finite difference\n",
      "scheme on the regular subdomain, but also can calculate $\\mathbf{VERY}$\n",
      "$\\mathbf{BIG}$ jump ratio(such as $10^{12}:1$ or $1:10^{12}$) for the interface\n",
      "problems including degenerate and non-degenerate cases. The expansion of the\n",
      "solutions does not contains any undetermined parameters in the numerical\n",
      "method. In this way, two independent nonlinear systems are constructed in other\n",
      "subdomains and can be computed in parallel. The flexibility, accuracy and\n",
      "efficiency of the methods are validated from various experiments in both 1D and\n",
      "2D. Specially, not only our method is suitable for solving degenerate interface\n",
      "case, but also for non-degenerate interface case. Some application examples\n",
      "with complicated multi-connected and sharp edge interface examples including\n",
      "degenerate and nondegenerate cases are also presented.\n",
      "\n",
      "\n",
      " Concepts: interface, degenerate, problems, numerical, decoupled\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the main motivation paper construct fully decoupled numerical methods solving degenerate?\n",
      "  2. degenerate<sep>\n",
      "  3. What is the main motivation paper construct fully decoupled numerical methods solving degenerate interface?\n",
      "================================================================================\n",
      "\n",
      " Abstract 633999:\n",
      "  The A-hierarchy is a parametric analogue of the polynomial hierarchy in the\n",
      "context of paramterised complexity theory. We give a new characterisation of\n",
      "the A-hierarchy in terms of a generalisation of the SUBSET-SUM problem.\n",
      "\n",
      "\n",
      " Concepts: problem, ahierarchy, parametric, analogue, polynomial\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the generalisation subsetsum?\n",
      "  2. What type of terms generalisation subsetsum problem does generalisation subsetsum give new characterisation?\n",
      "  3. What type of hierarchy context is ahierarchy?\n",
      "================================================================================\n",
      "\n",
      " Abstract 226683:\n",
      "  Text generation from AMR involves emitting sentences that reflect the meaning\n",
      "of their AMR annotations. Neural sequence-to-sequence models have successfully\n",
      "been used to decode strings from flattened graphs (e.g., using depth-first or\n",
      "random traversal). Such models often rely on attention-based decoders to map\n",
      "AMR node to English token sequences. Instead of linearizing AMR, we directly\n",
      "encode its graph structure and delegate traversal to the decoder. To enforce a\n",
      "sentence-aligned graph traversal and provide local graph context, we predict\n",
      "transition-based parser actions in addition to English words. We present two\n",
      "model variants: one generates parser actions prior to words, while the other\n",
      "interleaves actions with words.\n",
      "\n",
      "\n",
      " Concepts: actions, amr, parser, traversal, words\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does one generate byser?\n",
      "  2. What type of annotations does text generation involve?\n",
      "  3. What is one of the two model variants of amr node english token sequences?\n",
      "================================================================================\n",
      "\n",
      " Abstract 41044:\n",
      "  Tags assigned by users to shared content can be ambiguous. As a possible\n",
      "solution, we propose semantic tagging as a collaborative process in which a\n",
      "user selects and associates Web resources drawn from a knowledge context. We\n",
      "applied this general technique in the specific context of online historical\n",
      "maps and allowed users to annotate and tag them. To study the effects of\n",
      "semantic tagging on tag production, the types and categories of obtained tags,\n",
      "and user task load, we conducted an in-lab within-subject experiment with 24\n",
      "participants who annotated and tagged two distinct maps. We found that the\n",
      "semantic tagging implementation does not affect these parameters, while\n",
      "providing tagging relationships to well-defined concept definitions. Compared\n",
      "to label-based tagging, our technique also gathers positive and negative\n",
      "tagging relationships. We believe that our findings carry implications for\n",
      "designers who want to adopt semantic tagging in other contexts and systems on\n",
      "the Web.\n",
      "\n",
      "\n",
      " Concepts: tagging, semantic, relationships, web, technique\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does semantic mean?\n",
      "  2. What type of tagging contexts systems web resources were used to create tags?\n",
      "  3. What do people believe findings carry implications?\n",
      "================================================================================\n",
      "\n",
      " Abstract 633440:\n",
      "  Open source software (OSS) is integral to modern product development, and any\n",
      "vulnerability within it potentially compromises numerous products. While\n",
      "developers strive to apply security patches, pinpointing these patches among\n",
      "extensive OSS updates remains a challenge. Security patch localization (SPL)\n",
      "recommendation methods are leading approaches to address this. However,\n",
      "existing SPL models often falter when a commit lacks a clear association with\n",
      "its corresponding CVE, and do not consider a scenario that a vulnerability has\n",
      "multiple patches proposed over time before it has been fully resolved. To\n",
      "address these challenges, we introduce LLM-SPL, a recommendation-based SPL\n",
      "approach that leverages the capabilities of the Large Language Model (LLM) to\n",
      "locate the security patch commit for a given CVE. More specifically, we propose\n",
      "a joint learning framework, in which the outputs of LLM serves as additional\n",
      "features to aid our recommendation model in prioritizing security patches. Our\n",
      "evaluation on a dataset of 1,915 CVEs associated with 2,461 patches\n",
      "demonstrates that LLM-SPL excels in ranking patch commits, surpassing the\n",
      "state-of-the-art method in terms of Recall, while significantly reducing manual\n",
      "effort. Notably, for vulnerabilities requiring multiple patches, LLM-SPL\n",
      "significantly improves Recall by 22.83\\%, NDCG by 19.41\\%, and reduces manual\n",
      "effort by over 25\\% when checking up to the top 10 rankings. The dataset and\n",
      "source code are available at\n",
      "\\url{https://anonymous.4open.science/r/LLM-SPL-91F8}.\n",
      "\n",
      "\n",
      " Concepts: patches, security, patch, spl, llmspl\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is llmspl's ranking patch commits a significant improvement in recall?\n",
      "  2. What is the key to a product development vulnerability?\n",
      "  3. What is llmspl's ranking a spl recommendation model?\n",
      "================================================================================\n",
      "\n",
      " Abstract 253766:\n",
      "  Many real-world problems require trading off multiple competing objectives.\n",
      "However, these objectives are often in different units and/or scales, which can\n",
      "make it challenging for practitioners to express numerical preferences over\n",
      "objectives in their native units. In this paper we propose a novel algorithm\n",
      "for multi-objective reinforcement learning that enables setting desired\n",
      "preferences for objectives in a scale-invariant way. We propose to learn an\n",
      "action distribution for each objective, and we use supervised learning to fit a\n",
      "parametric policy to a combination of these distributions. We demonstrate the\n",
      "effectiveness of our approach on challenging high-dimensional real and\n",
      "simulated robotics tasks, and show that setting different preferences in our\n",
      "framework allows us to trace out the space of nondominated solutions.\n",
      "\n",
      "\n",
      " Concepts: objectives, preferences, units, challenging, propose\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the main reason for a multiobjective reinforcement learning?\n",
      "  2. What is the set of the target set in a novel algorithm?\n",
      "  3. What is the name of the paper that proposes novel algorithm multiobjective reinforcement learning?\n",
      "================================================================================\n",
      "\n",
      " Abstract 95473:\n",
      "  This paper presents a novel two-phase method for audio representation,\n",
      "Discriminative and Compact Audio Representation (DCAR), and evaluates its\n",
      "performance at detecting events in consumer-produced videos. In the first phase\n",
      "of DCAR, each audio track is modeled using a Gaussian mixture model (GMM) that\n",
      "includes several components to capture the variability within that track. The\n",
      "second phase takes into account both global structure and local structure. In\n",
      "this phase, the components are rendered more discriminative and compact by\n",
      "formulating an optimization problem on Grassmannian manifolds, which we found\n",
      "represents the structure of audio effectively.\n",
      "  Our experiments used the YLI-MED dataset (an open TRECVID-style video corpus\n",
      "based on YFCC100M), which includes ten events. The results show that the\n",
      "proposed DCAR representation consistently outperforms state-of-the-art audio\n",
      "representations. DCAR's advantage over i-vector, mv-vector, and GMM\n",
      "representations is significant for both easier and harder discrimination tasks.\n",
      "We discuss how these performance differences across easy and hard cases follow\n",
      "from how each type of model leverages (or doesn't leverage) the intrinsic\n",
      "structure of the data. Furthermore, DCAR shows a particularly notable accuracy\n",
      "advantage on events where humans have more difficulty classifying the videos,\n",
      "i.e., events with lower mean annotator confidence.\n",
      "\n",
      "\n",
      " Concepts: audio, events, structure, dcar, representation\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the term for dcar representation?\n",
      "  2. What is the lower mean annotator confidence?\n",
      "  3. What structure does the gaussian mixture model gmm have?\n",
      "================================================================================\n",
      "\n",
      " Abstract 507473:\n",
      "  Despite rapid progress in the voice style transfer (VST) field, recent\n",
      "zero-shot VST systems still lack the ability to transfer the voice style of a\n",
      "novel speaker. In this paper, we present HierVST, a hierarchical adaptive\n",
      "end-to-end zero-shot VST model. Without any text transcripts, we only use the\n",
      "speech dataset to train the model by utilizing hierarchical variational\n",
      "inference and self-supervised representation. In addition, we adopt a\n",
      "hierarchical adaptive generator that generates the pitch representation and\n",
      "waveform audio sequentially. Moreover, we utilize unconditional generation to\n",
      "improve the speaker-relative acoustic capacity in the acoustic representation.\n",
      "With a hierarchical adaptive structure, the model can adapt to a novel voice\n",
      "style and convert speech progressively. The experimental results demonstrate\n",
      "that our method outperforms other VST models in zero-shot VST scenarios. Audio\n",
      "samples are available at \\url{https://hiervst.github.io/}.\n",
      "\n",
      "\n",
      " Concepts: vst, hierarchical, voice, style, zeroshot\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the case with githubio?\n",
      "  2. What is the adaptive generator used to generate pitch representation waveform audio sequentially moreover utilize unconditional generation improve speakerrelative acoustic capacity acoustic representation?\n",
      "  3. What style novel speaker paper present hiervst hierarchical adaptive endtoend zeroshot vst model without text transcripts?\n",
      "================================================================================\n",
      "\n",
      " Abstract 709584:\n",
      "  We study memory-efficient matrix factorization for differentially private\n",
      "counting under continual observation. While recent work by Henzinger and\n",
      "Upadhyay 2024 introduced a factorization method with reduced error based on\n",
      "group algebra, its practicality in streaming settings remains limited by\n",
      "computational constraints. We present new structural properties of the group\n",
      "algebra factorization, enabling the use of a binning technique from Andersson\n",
      "and Pagh (2024). By grouping similar values in rows, the binning method reduces\n",
      "memory usage and running time to $\\tilde O(\\sqrt{n})$, where $n$ is the length\n",
      "of the input stream, while maintaining a low error. Our work bridges the gap\n",
      "between theoretical improvements in factorization accuracy and practical\n",
      "efficiency in large-scale private learning systems.\n",
      "\n",
      "\n",
      " Concepts: factorization, group, algebra, private, work\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the study memoryefficient matrix?\n",
      "  2. What group of ing similar values rows binning method reduces memory usage?\n",
      "  3. What is the main component of factorization?\n",
      "================================================================================\n",
      "\n",
      " Abstract 534995:\n",
      "  We present an efficient framework for solving algebraically-constrained\n",
      "global non-convex polynomial optimization problems over subsets of the\n",
      "hypercube. We prove the existence of an equivalent nonlinear reformulation of\n",
      "such problems that possesses essentially no spurious local minima. Through\n",
      "numerical experiments on previously intractable global constrained polynomial\n",
      "optimization problems in high dimension, we show that polynomial scaling in\n",
      "dimension and degree is achievable when computing the optimal value and\n",
      "location.\n",
      "\n",
      "\n",
      " Concepts: optimization, polynomial, problems, present, location\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the main problem of hypercube?\n",
      "  2. What type of optimization problems high dimension show?\n",
      "  3. What is the present efficient framework solving algebraicallyconstrained global nonconvex polynomial optimization?\n",
      "================================================================================\n",
      "\n",
      " Abstract 680108:\n",
      "  Large Language Models (LLMs) excel at rewriting tasks such as text style\n",
      "transfer and grammatical error correction. While there is considerable overlap\n",
      "between the inputs and outputs in these tasks, the decoding cost still\n",
      "increases with output length, regardless of the amount of overlap. By\n",
      "leveraging the overlap between the input and the output, Kaneko and Okazaki\n",
      "(2023) proposed model-agnostic edit span representations to compress the\n",
      "rewrites to save computation. They reported an output length reduction rate of\n",
      "nearly 80% with minimal accuracy impact in four rewriting tasks. In this paper,\n",
      "we propose alternative edit phrase representations inspired by phrase-based\n",
      "statistical machine translation. We systematically compare our phrasal\n",
      "representations with their span representations. We apply the LLM rewriting\n",
      "model to the task of Automatic Speech Recognition (ASR) post editing and show\n",
      "that our target-phrase-only edit representation has the best\n",
      "efficiency-accuracy trade-off. On the LibriSpeech test set, our method closes\n",
      "50-60% of the WER gap between the edit span model and the full rewrite model\n",
      "while losing only 10-20% of the length reduction rate of the edit span model.\n",
      "\n",
      "\n",
      " Concepts: span, edit, length, reduction, rewriting\n",
      "\n",
      " Generated Questions:\n",
      "  1. What model loses 1020 length reduction rate edit?\n",
      "  2. What is the result of a rewriting model?\n",
      "  3. What is the reduction rate of edit span model?\n",
      "================================================================================\n",
      "\n",
      " Abstract 115562:\n",
      "  This paper describes the full- and reduced-order models of an actuated\n",
      "hydraulic cylinder suitable for system dynamics analysis and motion control\n",
      "design. The full-order model incorporates the valve spool dynamics with\n",
      "combined dead-zone and saturation nonlinearities - inherent for the orifice\n",
      "flow. It includes the continuity equations of hydraulic circuits coupled with\n",
      "the dynamics of mechanical part of cylinder drive. The resulted model is the\n",
      "fifth-order and nonlinear in states. The reduced model neglects the fast valve\n",
      "spool dynamics, simplifies both the orifice and continuity equations through an\n",
      "aggregation, and considers the cylinder rod velocity as output of interest. The\n",
      "reduced model is second-order that facilitates studying the system behavior and\n",
      "allows for direct phase plane analysis. Dynamics properties are addressed in\n",
      "details, for both models, with focus on the frequency response, system damping,\n",
      "and state trajectories related to the load pressure and relative velocity.\n",
      "\n",
      "\n",
      " Concepts: dynamics, spool, model, cylinder, system\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does the full order model incorporates?\n",
      "  2. What does the fullorder model incorporates valve?\n",
      "  3. What model incorporates valve spool dynamics combined deadzone saturation nonlinearities inherent orifice flow simplifies orifice continuity equations?\n",
      "================================================================================\n",
      "\n",
      " Abstract 31999:\n",
      "  In this paper we describe a general probabilistic framework for modeling\n",
      "waveforms such as heartbeats from ECG data. The model is based on segmental\n",
      "hidden Markov models (as used in speech recognition) with the addition of\n",
      "random effects to the generative model. The random effects component of the\n",
      "model handles shape variability across different waveforms within a general\n",
      "class of waveforms of similar shape. We show that this probabilistic model\n",
      "provides a unified framework for learning these models from sets of waveform\n",
      "data as well as parsing, classification, and prediction of new waveforms. We\n",
      "derive a computationally efficient EM algorithm to fit the model on multiple\n",
      "waveforms, and introduce a scoring method that evaluates a test waveform based\n",
      "on its shape. Results on two real-world data sets demonstrate that the random\n",
      "effects methodology leads to improved accuracy (compared to alternative\n",
      "approaches) on classification and segmentation of real-world waveforms.\n",
      "\n",
      "\n",
      " Concepts: waveforms, random, effects, model, data\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the model that provides unified framework learning models sets?\n",
      "  2. What is the effect methodology that handles shape variability across different waveforms within general class waveforms?\n",
      "  3. What is the random em algorithm that evaluates test waveform based shape results?\n",
      "================================================================================\n",
      "\n",
      " Abstract 652509:\n",
      "  Modern deep learning models often make predictions by focusing on irrelevant\n",
      "areas, leading to biased performance and limited generalization. Existing\n",
      "methods aimed at rectifying model attention require explicit labels for\n",
      "irrelevant areas or complex pixel-wise ground truth attention maps. We present\n",
      "CRAYON (Correcting Reasoning with Annotations of Yes Or No), offering\n",
      "effective, scalable, and practical solutions to rectify model attention using\n",
      "simple yes-no annotations. CRAYON empowers classical and modern model\n",
      "interpretation techniques to identify and guide model reasoning:\n",
      "CRAYON-ATTENTION directs classic interpretations based on saliency maps to\n",
      "focus on relevant image regions, while CRAYON-PRUNING removes irrelevant\n",
      "neurons identified by modern concept-based methods to mitigate their influence.\n",
      "Through extensive experiments with both quantitative and human evaluation, we\n",
      "showcase CRAYON's effectiveness, scalability, and practicality in refining\n",
      "model attention. CRAYON achieves state-of-the-art performance, outperforming 12\n",
      "methods across 3 benchmark datasets, surpassing approaches that require more\n",
      "complex annotations.\n",
      "\n",
      "\n",
      " Concepts: attention, model, irrelevant, modern, methods\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does crayon correcting reasoning annotations yes offering effective scalable practical solutions rectify model?\n",
      "  2. What is the modern deep learning model?\n",
      "  3. What is the main area that is focusing on model attention?\n",
      "================================================================================\n",
      "\n",
      " Abstract 73740:\n",
      "  High dimensional regression benefits from sparsity promoting regularizations.\n",
      "Screening rules leverage the known sparsity of the solution by ignoring some\n",
      "variables in the optimization, hence speeding up solvers. When the procedure is\n",
      "proven not to discard features wrongly the rules are said to be \\emph{safe}. In\n",
      "this paper we derive new safe rules for generalized linear models regularized\n",
      "with $\\ell_1$ and $\\ell_1/\\ell_2$ norms. The rules are based on duality gap\n",
      "computations and spherical safe regions whose diameters converge to zero. This\n",
      "allows to discard safely more variables, in particular for low regularization\n",
      "parameters. The GAP Safe rule can cope with any iterative solver and we\n",
      "illustrate its performance on coordinate descent for multi-task Lasso, binary\n",
      "and multinomial logistic regression, demonstrating significant speed ups on all\n",
      "tested datasets with respect to previous safe rules.\n",
      "\n",
      "\n",
      " Concepts: safe, rules, regression, sparsity, variables\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of rules does emph derive?\n",
      "  2. What is the name of the rule that is used to describe the emphsafe paper?\n",
      "  3. What benefits sparsity promoting regularizations screening rules leverage known sparsity solution ignoring variables optimization hence speeding solvers procedure proven discard features wrongly rules said discard features wrongly rules said emphsafe paper derive new safe rules generalized linear models regularized ell1 ell\n",
      "================================================================================\n",
      "\n",
      " Abstract 79352:\n",
      "  We consider the supervised training setting in which we learn task-specific\n",
      "word embeddings. We assume that we start with initial embeddings learned from\n",
      "unlabelled data and update them to learn task-specific embeddings for words in\n",
      "the supervised training data. However, for new words in the test set, we must\n",
      "use either their initial embeddings or a single unknown embedding, which often\n",
      "leads to errors. We address this by learning a neural network to map from\n",
      "initial embeddings to the task-specific embedding space, via a multi-loss\n",
      "objective function. The technique is general, but here we demonstrate its use\n",
      "for improved dependency parsing (especially for sentences with\n",
      "out-of-vocabulary words), as well as for downstream improvements on sentiment\n",
      "analysis.\n",
      "\n",
      "\n",
      " Concepts: embeddings, taskspecific, initial, words, supervised\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the first word to be used in supervised training?\n",
      "  2. What is the term for embeddings words?\n",
      "  3. What is the first step in supervised training?\n",
      "================================================================================\n",
      "\n",
      " Abstract 661929:\n",
      "  In recent decades, statisticians have been increasingly encountering spatial\n",
      "data that exhibit non-Gaussian behaviors such as asymmetry and\n",
      "heavy-tailedness. As a result, the assumptions of symmetry and fixed tail\n",
      "weight in Gaussian processes have become restrictive and may fail to capture\n",
      "the intrinsic properties of the data. To address the limitations of the\n",
      "Gaussian models, a variety of skewed models has been proposed, of which the\n",
      "popularity has grown rapidly. These skewed models introduce parameters that\n",
      "govern skewness and tail weight. Among various proposals in the literature,\n",
      "unified skewed distributions, such as the Unified Skew-Normal (SUN), have\n",
      "received considerable attention. In this work, we revisit a more concise and\n",
      "intepretable re-parameterization of the SUN distribution and apply the\n",
      "distribution to random fields by constructing a generalized unified skew-normal\n",
      "(GSUN) spatial process. We demonstrate that the GSUN is a valid spatial process\n",
      "by showing its vanishing correlation in large distances and provide the\n",
      "corresponding spatial interpolation method. In addition, we develop an\n",
      "inference mechanism for the GSUN process using the concept of neural Bayes\n",
      "estimators with deep graphical attention networks (GATs) and encoder\n",
      "transformer. We show the superiority of our proposed estimator over the\n",
      "conventional CNN-based architectures regarding stability and accuracy by means\n",
      "of a simulation study and application to Pb-contaminated soil data.\n",
      "Furthermore, we show that the GSUN process is different from the conventional\n",
      "Gaussian processes and Tukey g-and-h processes, through the probability\n",
      "integral transform (PIT).\n",
      "\n",
      "\n",
      " Concepts: process, spatial, gsun, gaussian, processes\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is gsun a valid spatial gaussian?\n",
      "  2. What type of data exhibit nongaussian behaviors?\n",
      "  3. What is the vanishing correlation of a skewnormal process?\n",
      "================================================================================\n",
      "\n",
      " Abstract 386779:\n",
      "  This notes explains how standard algorithms that construct sorting networks\n",
      "have been formalised and proved correct in the Coq proof assistant using the\n",
      "SSReflect extension.\n",
      "\n",
      "\n",
      " Concepts: notes, extension, explains, standard, algorithms\n",
      "\n",
      " Generated Questions:\n",
      "  1. What explains standard algorithms construct sorting networks formalised proved correct coq proof assistant?\n",
      "  2. What is the name of the method used to describe the standard algorithms?\n",
      "  3. What does notes ssreflect extension do?\n",
      "================================================================================\n",
      "\n",
      " Abstract 382315:\n",
      "  Artificial intelligence and machine learning have been integrated into all\n",
      "aspects of our lives and the privacy of personal data has attracted more and\n",
      "more attention. Since the generation of the model needs to extract the\n",
      "effective information of the training data, the model has the risk of leaking\n",
      "the privacy of the training data. Membership inference attacks can measure the\n",
      "model leakage of source data to a certain degree. In this paper, we design a\n",
      "privacy-preserving generative framework against membership inference attacks,\n",
      "through the information extraction and data generation capabilities of the\n",
      "generative model variational autoencoder (VAE) to generate synthetic data that\n",
      "meets the needs of differential privacy. Instead of adding noise to the model\n",
      "output or tampering with the training process of the target model, we directly\n",
      "process the original data. We first map the source data to the latent space\n",
      "through the VAE model to get the latent code, then perform noise process\n",
      "satisfying metric privacy on the latent code, and finally use the VAE model to\n",
      "reconstruct the synthetic data. Our experimental evaluation demonstrates that\n",
      "the machine learning model trained with newly generated synthetic data can\n",
      "effectively resist membership inference attacks and still maintain high\n",
      "utility.\n",
      "\n",
      "\n",
      " Concepts: data, model, inference, membership, attacks\n",
      "\n",
      " Generated Questions:\n",
      "  1. What data does the model model leakage source?\n",
      "  2. what model will produce synthetic data meets needs differential privacy?\n",
      "  3. What is the name of the attack that keeps high utility?\n",
      "================================================================================\n",
      "\n",
      " Abstract 632030:\n",
      "  Automorphism-ensemble decoding is applied to the Plotkin constituents of\n",
      "Reed-Muller codes, resulting in a new soft-decision decoding algorithm with\n",
      "state-of-the-art performance versus complexity trade-offs.\n",
      "\n",
      "\n",
      " Concepts: automorphismensemble, tradeoffs, decoding, applied, plotkin\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of decoding applied plotkin constituents reedmuller codes resulted in a new softdecision decoding algorithm?\n",
      "  2. What is the new softdecision decoding algorithm stateoftheart performance versus complexity?\n",
      "  3. What is the automorphism ensemble?\n",
      "================================================================================\n",
      "\n",
      " Abstract 52647:\n",
      "  Maximum Flow Network Interdiction Problem (MFNIP) is known to be strongly\n",
      "NP-hard problem. We solve a simple form of MFNIP in polynomial time. We review\n",
      "the reduction of MFNIP from the clique problem. We propose a polynomial time\n",
      "solution to the Clique Problem.\n",
      "\n",
      "\n",
      " Concepts: problem, polynomial, time, clique, mfnip\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the most common problem with maximum flow network interdiction?\n",
      "  2. What is the term for the time solution clique problem?\n",
      "  3. What is the solution to clique problem?\n",
      "================================================================================\n",
      "\n",
      " Abstract 392677:\n",
      "  Annotating tens or hundreds of tiny objects in a given image is laborious yet\n",
      "crucial for a multitude of Computer Vision tasks. Such imagery typically\n",
      "contains objects from various categories, yet the multi-class interactive\n",
      "annotation setting for the detection task has thus far been unexplored. To\n",
      "address these needs, we propose a novel interactive annotation method for\n",
      "multiple instances of tiny objects from multiple classes, based on a few\n",
      "point-based user inputs. Our approach, C3Det, relates the full image context\n",
      "with annotator inputs in a local and global manner via late-fusion and\n",
      "feature-correlation, respectively. We perform experiments on the Tiny-DOTA and\n",
      "LCell datasets using both two-stage and one-stage object detection\n",
      "architectures to verify the efficacy of our approach. Our approach outperforms\n",
      "existing approaches in interactive annotation, achieving higher mAP with fewer\n",
      "clicks. Furthermore, we validate the annotation efficiency of our approach in a\n",
      "user study where it is shown to be 2.85x faster and yield only 0.36x task load\n",
      "(NASA-TLX, lower is better) compared to manual annotation. The code is\n",
      "available at\n",
      "https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection.\n",
      "\n",
      "\n",
      " Concepts: annotation, interactive, approach, objects, tiny\n",
      "\n",
      " Generated Questions:\n",
      "  1. What method is used to validate a user study?\n",
      "  2. What method is multiclass?\n",
      "  3. What approach outperforms existing?\n",
      "================================================================================\n",
      "\n",
      " Abstract 150579:\n",
      "  Stochastic gradient descent is the method of choice for large scale\n",
      "optimization of machine learning objective functions. Yet, its performance is\n",
      "greatly variable and heavily depends on the choice of the stepsizes. This has\n",
      "motivated a large body of research on adaptive stepsizes. However, there is\n",
      "currently a gap in our theoretical understanding of these methods, especially\n",
      "in the non-convex setting. In this paper, we start closing this gap: we\n",
      "theoretically analyze in the convex and non-convex settings a generalized\n",
      "version of the AdaGrad stepsizes. We show sufficient conditions for these\n",
      "stepsizes to achieve almost sure asymptotic convergence of the gradients to\n",
      "zero, proving the first guarantee for generalized AdaGrad stepsizes in the\n",
      "non-convex setting. Moreover, we show that these stepsizes allow to\n",
      "automatically adapt to the level of noise of the stochastic gradients in both\n",
      "the convex and non-convex settings, interpolating between $O(1/T)$ and\n",
      "$O(1/\\sqrt{T})$, up to logarithmic terms.\n",
      "\n",
      "\n",
      " Concepts: nonconvex, stepsizes, stochastic, convex, adagrad\n",
      "\n",
      " Generated Questions:\n",
      "  1. What setting does the current gap theoretical understanding methods especially include?\n",
      "  2. What does adagrad's performance greatly variable depend choice?\n",
      "  3. What type of gradient is it?\n",
      "================================================================================\n",
      "\n",
      " Abstract 382049:\n",
      "  A spatial active noise control (ANC) method based on the individual kernel\n",
      "interpolation of primary and secondary sound fields is proposed. Spatial ANC is\n",
      "aimed at cancelling unwanted primary noise within a continuous region by using\n",
      "multiple secondary sources and microphones. A method based on the kernel\n",
      "interpolation of a sound field makes it possible to attenuate noise over the\n",
      "target region with flexible array geometry. Furthermore, by using the kernel\n",
      "function with directional weighting, prior information on primary noise source\n",
      "directions can be taken into consideration. However, whereas the sound field to\n",
      "be interpolated is a superposition of primary and secondary sound fields, the\n",
      "directional weight for the primary noise source was applied to the total sound\n",
      "field in previous work; therefore, the performance improvement was limited. We\n",
      "propose a method of individually interpolating the primary and secondary sound\n",
      "fields and formulate a normalized least-mean-square algorithm based on this\n",
      "interpolation method. Experimental results indicate that the proposed method\n",
      "outperforms the method based on total kernel interpolation.\n",
      "\n",
      "\n",
      " Concepts: sound, primary, secondary, noise, method\n",
      "\n",
      " Generated Questions:\n",
      "  1. What field makes possible attenuate noise target region flexible array geometry furthermore using kernel function directional weighting prior information primary noise source directions taken consideration?\n",
      "  2. What is the primary sound field interpolated superposition?\n",
      "  3. What type of sound fields are proposed spatial anc aimed at cancelling unwanted primary noise within continuous region?\n",
      "================================================================================\n",
      "\n",
      " Abstract 10531:\n",
      "  The paper first recalls the Blahut Arimoto algorithm for computing the\n",
      "capacity of arbitrary discrete memoryless channels, as an example of an\n",
      "iterative algorithm working with probability density estimates. Then, a\n",
      "geometrical interpretation of this algorithm based on projections onto linear\n",
      "and exponential families of probabilities is provided. Finally, this\n",
      "understanding allows also to propose to write the Blahut-Arimoto algorithm, as\n",
      "a true proximal point algorithm. it is shown that the corresponding version has\n",
      "an improved convergence rate, compared to the initial algorithm, as well as in\n",
      "comparison with other improved versions.\n",
      "\n",
      "\n",
      " Concepts: algorithm, improved, paper, recalls, blahut\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the first algorithm that proposes a better version of the blahutarimoto?\n",
      "  2. What improved version of true proximal point algorithm shown corresponding version?\n",
      "  3. What is the first paper to recall blahut arimoto algorithm?\n",
      "================================================================================\n",
      "\n",
      " Abstract 216615:\n",
      "  The paper presents a direct visual-inertial odometry system. In particular, a\n",
      "tightly coupled nonlinear optimization based method is proposed by integrating\n",
      "the recent advances in direct dense tracking and Inertial Measurement Unit\n",
      "(IMU) pre-integration, and a factor graph optimization is adapted to estimate\n",
      "the pose of the camera and rebuild a semi-dense map. Two sliding windows are\n",
      "maintained in the proposed approach. The first one, based on Direct Sparse\n",
      "Odometry (DSO), is to estimate the depths of candidate points for mapping and\n",
      "dense visual tracking. In the second one, measurements from the IMU\n",
      "pre-integration and dense visual tracking are fused probabilistically using a\n",
      "tightly-coupled, optimization-based sensor fusion framework. As a result, the\n",
      "IMU pre-integration provides additional constraints to suppress the scale drift\n",
      "induced by the visual odometry. Evaluations on real-world benchmark datasets\n",
      "show that the proposed method achieves competitive results in indoor scenes.\n",
      "\n",
      "\n",
      " Concepts: imu, preintegration, visual, dense, tracking\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the preintegration factor graph optimization?\n",
      "  2. What is imu a factor graph optimization adapted estimate pose camera rebuild semidense map two sliding windows maintained semidense map two sliding windows maintained?\n",
      "  3. What is the direct odometry system?\n",
      "================================================================================\n",
      "\n",
      " Abstract 35260:\n",
      "  The incidence of thyroid nodule is very high and generally increases with the\n",
      "age. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\n",
      "nodule can be completely cured if detected early. Fine needle aspiration\n",
      "cytology is a recognized early diagnosis method of thyroid nodule. There are\n",
      "still some limitations in the fine needle aspiration cytology, and the\n",
      "ultrasound diagnosis of thyroid nodule has become the first choice for\n",
      "auxiliary examination of thyroid nodular disease. If we could combine medical\n",
      "imaging technology and fine needle aspiration cytology, the diagnostic rate of\n",
      "thyroid nodule would be improved significantly. The properties of ultrasound\n",
      "will degrade the image quality, which makes it difficult to recognize the edges\n",
      "for physicians. Image segmentation technique based on graph theory has become a\n",
      "research hotspot at present. Normalized cut (Ncut) is a representative one,\n",
      "which is suitable for segmentation of feature parts of medical image. However,\n",
      "how to solve the normalized cut has become a problem, which needs large memory\n",
      "capacity and heavy calculation of weight matrix. It always generates over\n",
      "segmentation or less segmentation which leads to inaccurate in the\n",
      "segmentation. The speckle noise in B ultrasound image of thyroid tumor makes\n",
      "the quality of the image deteriorate. In the light of this characteristic, we\n",
      "combine the anisotropic diffusion model with the normalized cut in this paper.\n",
      "After the enhancement of anisotropic diffusion model, it removes the noise in\n",
      "the B ultrasound image while preserves the important edges and local details.\n",
      "This reduces the amount of computation in constructing the weight matrix of the\n",
      "improved normalized cut and improves the accuracy of the final segmentation\n",
      "results. The feasibility of the method is proved by the experimental results.\n",
      "\n",
      "\n",
      " Concepts: thyroid, nodule, needle, aspiration, normalized\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the first choice auxiliary examination?\n",
      "  2. What is the primary cause of emergence thyroid cancer?\n",
      "  3. What is the name of the aspiration cytology ultrasound diagnosis thyroid nodule still limitations?\n",
      "================================================================================\n",
      "\n",
      " Abstract 102130:\n",
      "  We consider the problem of influence maximization in fixed networks for\n",
      "contagion models in an adversarial setting. The goal is to select an optimal\n",
      "set of nodes to seed the influence process, such that the number of influenced\n",
      "nodes at the conclusion of the campaign is as large as possible. We formulate\n",
      "the problem as a repeated game between a player and adversary, where the\n",
      "adversary specifies the edges along which the contagion may spread, and the\n",
      "player chooses sets of nodes to influence in an online fashion. We establish\n",
      "upper and lower bounds on the minimax pseudo-regret in both undirected and\n",
      "directed networks.\n",
      "\n",
      "\n",
      " Concepts: nodes, influence, problem, networks, contagion\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the result of a successful campaign?\n",
      "  2. What is the result of a problem?\n",
      "  3. What is the best set nodes seed influence process?\n",
      "================================================================================\n",
      "\n",
      " Abstract 636028:\n",
      "  Over the last two decades, several fast, robust, and high-order accurate\n",
      "methods have been developed for solving the Poisson equation in complicated\n",
      "geometry using potential theory. In this approach, rather than discretizing the\n",
      "partial differential equation itself, one first evaluates a volume integral to\n",
      "account for the source distribution within the domain, followed by solving a\n",
      "boundary integral equation to impose the specified boundary conditions. Here,\n",
      "we present a new fast algorithm which is easy to implement and compatible with\n",
      "virtually any discretization technique, including unstructured domain\n",
      "triangulations, such as those used in standard finite element or finite volume\n",
      "methods. Our approach combines earlier work on potential theory for the heat\n",
      "equation, asymptotic analysis, the nonuniform fast Fourier transform (NUFFT),\n",
      "and the dual-space multilevel kernel-splitting (DMK) framework. It is\n",
      "insensitive to flaws in the triangulation, permitting not just nonconforming\n",
      "elements, but arbitrary aspect ratio triangles, gaps and various other\n",
      "degeneracies. On a single CPU core, the scheme computes the solution at a rate\n",
      "comparable to that of the fast Fourier transform (FFT) in work per gridpoint.\n",
      "\n",
      "\n",
      " Concepts: fast, fourier, equation, potential, theory\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the new algorithm easy implement compatible virtually discretization technique including unstructured domain triangulations?\n",
      "  2. What transform fft work per gridpoint?\n",
      "  3. What is the term for a method that combines a theoretical approach?\n",
      "================================================================================\n",
      "\n",
      " Abstract 705847:\n",
      "  Effectively searching time-series data is essential for system analysis;\n",
      "however, traditional methods often require domain expertise to define search\n",
      "criteria. Recent advancements have enabled natural language-based search, but\n",
      "these methods struggle to handle differences between time-series data. To\n",
      "address this limitation, we propose a natural language query-based approach for\n",
      "retrieving pairs of time-series data based on differences specified in the\n",
      "query. Specifically, we define six key characteristics of differences,\n",
      "construct a corresponding dataset, and develop a contrastive learning-based\n",
      "model to align differences between time-series data with query texts.\n",
      "Experimental results demonstrate that our model achieves an overall mAP score\n",
      "of 0.994 in retrieving time-series pairs.\n",
      "\n",
      "\n",
      " Concepts: timeseries, data, differences, methods, define\n",
      "\n",
      " Generated Questions:\n",
      "  1. What data query texts experimental results demonstrate model achieves overall map score 0994 retrieving?\n",
      "  2. What is the main component of a traditional search method?\n",
      "  3. What is the corresponding dataset developed?\n",
      "================================================================================\n",
      "\n",
      " Abstract 140346:\n",
      "  We propose a new hybrid algorithm that allows incorporating both user and\n",
      "item side information within the standard collaborative filtering technique.\n",
      "One of its key features is that it naturally extends a simple PureSVD approach\n",
      "and inherits its unique advantages, such as highly efficient Lanczos-based\n",
      "optimization procedure, simplified hyper-parameter tuning and a quick\n",
      "folding-in computation for generating recommendations instantly even in highly\n",
      "dynamic online environments. The algorithm utilizes a generalized formulation\n",
      "of the singular value decomposition, which adds flexibility to the solution and\n",
      "allows imposing the desired structure on its latent space. Conveniently, the\n",
      "resulting model also admits an efficient and straightforward solution for the\n",
      "cold start scenario. We evaluate our approach on a diverse set of datasets and\n",
      "show its superiority over similar classes of hybrid models.\n",
      "\n",
      "\n",
      " Concepts: propose, hybrid, algorithm, approach, highly\n",
      "\n",
      " Generated Questions:\n",
      "  1. What new hybrid algorithm allows incorporating user item side information within standard collaborative filtering technique?\n",
      "  2. What type of algorithm allows incorporating user item side information within standard collaborative filtering technique?\n",
      "  3. What is a new hybrid?\n",
      "================================================================================\n",
      "\n",
      " Abstract 441894:\n",
      "  Recently, transformer networks have outperformed traditional deep neural\n",
      "networks in natural language processing and show a large potential in many\n",
      "computer vision tasks compared to convolutional backbones. In the original\n",
      "transformer, readout tokens are used as designated vectors for aggregating\n",
      "information from other tokens. However, the performance of using readout tokens\n",
      "in a vision transformer is limited. Therefore, we propose a novel fusion\n",
      "strategy to integrate radar data into a dense prediction transformer network by\n",
      "reassembling camera representations with radar representations. Instead of\n",
      "using readout tokens, radar representations contribute additional depth\n",
      "information to a monocular depth estimation model and improve performance. We\n",
      "further investigate different fusion approaches that are commonly used for\n",
      "integrating additional modality in a dense prediction transformer network. The\n",
      "experiments are conducted on the nuScenes dataset, which includes camera\n",
      "images, lidar, and radar data. The results show that our proposed method yields\n",
      "better performance than the commonly used fusion strategies and outperforms\n",
      "existing convolutional depth estimation models that fuse camera images and\n",
      "radar.\n",
      "\n",
      "\n",
      " Concepts: transformer, radar, readout, tokens, prediction\n",
      "\n",
      " Generated Questions:\n",
      "  1. What network reassembling camera representations contribute additional depth information monocular depth estimation model improve performance investigate different fusion approaches commonly used?\n",
      "  2. What type of representations contribute additional depth information monocular depth estimation model improve performance investigate different fusion approaches?\n",
      "  3. What was the purpose of a transformer network reassembling camera representations radar representations instead of?\n",
      "================================================================================\n",
      "\n",
      " Abstract 675267:\n",
      "  In this paper we introduce the definition of equal-difference cyclotomic\n",
      "coset, and prove that in general any cyclotomic coset can be decomposed into a\n",
      "disjoint union of equal-difference subsets. Among the equal-difference\n",
      "decompositions of a cyclotomic coset, an important class consists of those in\n",
      "the form of cyclotomic decompositions, called the multiple equal-difference\n",
      "representations of the coset. There is an equivalent correspondence between the\n",
      "multiple equal-difference representations of $q$-cyclotomic cosets modulo $n$\n",
      "and the irreducible factorizations of $X^{n}-1$ in binomial form over finite\n",
      "extension fields of $\\mathbb{F}_{q}$. We give an explicit characterization of\n",
      "the multiple equal-difference representations of any $q$-cyclotomic coset\n",
      "modulo $n$, through which a criterion for $X^{n}-1$ factoring into irreducible\n",
      "binomials is obtained. In addition, we represent an algorithm to simplify the\n",
      "computation of the leaders of cyclotomic cosets.\n",
      "\n",
      "\n",
      " Concepts: equaldifference, cyclotomic, coset, representations, multiple\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the definition of cyclotomic coset?\n",
      "  2. What type of coset is a coset important class?\n",
      "  3. What is the definition of cyclotomic?\n",
      "================================================================================\n",
      "\n",
      " Abstract 331519:\n",
      "  Probing complex language models has recently revealed several insights into\n",
      "linguistic and semantic patterns found in the learned representations. In this\n",
      "article, we probe BERT specifically to understand and measure the relational\n",
      "knowledge it captures in its parametric memory. While probing for linguistic\n",
      "understanding is commonly applied to all layers of BERT as well as fine-tuned\n",
      "models, this has not been done for factual knowledge. We utilize existing\n",
      "knowledge base completion tasks (LAMA) to probe every layer of pre-trained as\n",
      "well as fine-tuned BERT models(ranking, question answering, NER). Our findings\n",
      "show that knowledge is not just contained in BERT's final layers. Intermediate\n",
      "layers contribute a significant amount (17-60%) to the total knowledge found.\n",
      "Probing intermediate layers also reveals how different types of knowledge\n",
      "emerge at varying rates. When BERT is fine-tuned, relational knowledge is\n",
      "forgotten. The extent of forgetting is impacted by the fine-tuning objective\n",
      "and the training data. We found that ranking models forget the least and retain\n",
      "more knowledge in their final layer compared to masked language modeling and\n",
      "question-answering. However, masked language modeling performed the best at\n",
      "acquiring new knowledge from the training data. When it comes to learning\n",
      "facts, we found that capacity and fact density are key factors. We hope this\n",
      "initial work will spur further research into understanding the parametric\n",
      "memory of language models and the effect of training objectives on factual\n",
      "knowledge. The code to repeat the experiments is publicly available on GitHub.\n",
      "\n",
      "\n",
      " Concepts: knowledge, language, models, layers, found\n",
      "\n",
      " Generated Questions:\n",
      "  1. What does lama probe reveal?\n",
      "  2. What model did probing complex masked?\n",
      "  3. What did probing complex language reveal several insights linguistic semantic patterns found learned representations?\n",
      "================================================================================\n",
      "\n",
      " Abstract 553485:\n",
      "  Daily monitoring of stress is a critical component of maintaining optimal\n",
      "physical and mental health. Physiological signals and contextual information\n",
      "have recently emerged as promising indicators for detecting instances of\n",
      "heightened stress. Nonetheless, developing a real-time monitoring system that\n",
      "utilizes both physiological and contextual data to anticipate stress levels in\n",
      "everyday settings while also gathering stress labels from participants\n",
      "represents a significant challenge. We present a monitoring system that\n",
      "objectively tracks daily stress levels by utilizing both physiological and\n",
      "contextual data in a daily-life environment. Additionally, we have integrated a\n",
      "smart labeling approach to optimize the ecological momentary assessment (EMA)\n",
      "collection, which is required for building machine learning models for stress\n",
      "detection. We propose a three-tier Internet-of-Things-based system architecture\n",
      "to address the challenges. We utilized a cross-validation technique to\n",
      "accurately estimate the performance of our stress models. We achieved the\n",
      "F1-score of 70\\% with a Random Forest classifier using both PPG and contextual\n",
      "data, which is considered an acceptable score in models built for everyday\n",
      "settings. Whereas using PPG data alone, the highest F1-score achieved is\n",
      "approximately 56\\%, emphasizing the significance of incorporating both PPG and\n",
      "contextual data in stress detection tasks.\n",
      "\n",
      "\n",
      " Concepts: contextual, stress, data, ppg, monitoring\n",
      "\n",
      " Generated Questions:\n",
      "  1. What type of data anticipates stress levels everyday settings also gathering stress labels participants represents significant challenge present monitoring system objectively tracks daily stress levels?\n",
      "  2. What is the key component of monitoring?\n",
      "  3. What is the most important factor in a realtime monitoring system?\n",
      "================================================================================\n",
      "\n",
      " Abstract 141474:\n",
      "  What makes humans so good at solving seemingly complex video games? Unlike\n",
      "computers, humans bring in a great deal of prior knowledge about the world,\n",
      "enabling efficient decision making. This paper investigates the role of human\n",
      "priors for solving video games. Given a sample game, we conduct a series of\n",
      "ablation studies to quantify the importance of various priors on human\n",
      "performance. We do this by modifying the video game environment to\n",
      "systematically mask different types of visual information that could be used by\n",
      "humans as priors. We find that removal of some prior knowledge causes a drastic\n",
      "degradation in the speed with which human players solve the game, e.g. from 2\n",
      "minutes to over 20 minutes. Furthermore, our results indicate that general\n",
      "priors, such as the importance of objects and visual consistency, are critical\n",
      "for efficient game-play. Videos and the game manipulations are available at\n",
      "https://rach0012.github.io/humanRL_website/\n",
      "\n",
      "\n",
      " Concepts: video, game, priors, minutes, knowledge\n",
      "\n",
      " Generated Questions:\n",
      "  1. What kind of games are humans able to solve?\n",
      "  2. What is a solitary game that is a solitary game?\n",
      "  3. What is the main reason for the degradation of human's game environment?\n",
      "================================================================================\n",
      "\n",
      " Abstract 301181:\n",
      "  We investigate the parameterized complexity of finding diverse sets of\n",
      "solutions to three fundamental combinatorial problems, two from the theory of\n",
      "matroids and the third from graph theory. The input to the Weighted Diverse\n",
      "Bases problem consists of a matroid $M$, a weight function\n",
      "$\\omega:E(M)\\to\\mathbb{N}$, and integers $k\\geq 1, d\\geq 0$. The task is to\n",
      "decide if there is a collection of $k$ bases $B_{1}, \\dotsc, B_{k}$ of $M$ such\n",
      "that the weight of the symmetric difference of any pair of these bases is at\n",
      "least $d$. This is a diverse variant of the classical matroid base packing\n",
      "problem. The input to the Weighted Diverse Common Independent Sets problem\n",
      "consists of two matroids $M_{1},M_{2}$ defined on the same ground set $E$, a\n",
      "weight function $\\omega:E\\to\\mathbb{N}$, and integers $k\\geq 1, d\\geq 0$. The\n",
      "task is to decide if there is a collection of $k$ common independent sets\n",
      "$I_{1}, \\dotsc, I_{k}$ of $M_{1}$ and $M_{2}$ such that the weight of the\n",
      "symmetric difference of any pair of these sets is at least $d$. This is\n",
      "motivated by the classical weighted matroid intersection problem. The input to\n",
      "the Diverse Perfect Matchings problem consists of a graph $G$ and integers\n",
      "$k\\geq 1, d\\geq 0$. The task is to decide if $G$ contains $k$ perfect matchings\n",
      "$M_{1},\\dotsc,M_{k}$ such that the symmetric difference of any two of these\n",
      "matchings is at least $d$.\n",
      "  We show that Weighted Diverse Bases and Weighted Diverse Common Independent\n",
      "Sets are both NP-hard, and derive fixed-parameter tractable (FPT) algorithms\n",
      "for all three problems with $(k,d)$ as the parameter.\n",
      "\n",
      "\n",
      " Concepts: dgeq, diverse, kgeq, task, weighted\n",
      "\n",
      " Generated Questions:\n",
      "  1. What is the name of the task decide collection k bases b1 dotsc ik m1 m2 weight symmetric difference pair bases least diverse variant classical matroid base packing problem input diverse perfect matchings problem consists two matroids m1m2 defined ground set e\n",
      "  2. What type of base packing problem is a matroid weight function omegaemtomathbbn integers kgeq 1 dgeq 0 task decide collection k bases b1 dotsc bk weight symmetric difference pair bases least show weighted ?\n",
      "  3. What is the weight of a graph g integer?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Print final Results\n",
    "\n",
    "# Display abstract, extracted concepts, and generated questions\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"\\n Abstract {idx}:\\n{row['abstract']}\\n\")\n",
    "    print(f\" Concepts: {', '.join(row['concepts'])}\\n\")\n",
    "    print(\" Generated Questions:\")\n",
    "    for i, question in enumerate(row['questions'], 1):\n",
    "        print(f\"  {i}. {question}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f9235b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:30:12.195144Z",
     "iopub.status.busy": "2025-04-14T19:30:12.194502Z",
     "iopub.status.idle": "2025-04-14T19:30:12.203939Z",
     "shell.execute_reply": "2025-04-14T19:30:12.202907Z"
    },
    "papermill": {
     "duration": 0.022038,
     "end_time": "2025-04-14T19:30:12.205318",
     "exception": false,
     "start_time": "2025-04-14T19:30:12.183280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword Extraction Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Keyword Extraction Accuracy\n",
    "def evaluate_keyword_extraction(sample_size=50):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Randomly sample abstracts\n",
    "    for _, row in sample_df.sample(sample_size).iterrows():\n",
    "        # Count as correct if keywords (concepts) are not empty\n",
    "        if len(row['concepts']) > 0:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    return correct / total  # Return basic accuracy\n",
    "\n",
    "# Run and print accuracy\n",
    "keyword_accuracy = evaluate_keyword_extraction()\n",
    "print(f\"Keyword Extraction Accuracy: {keyword_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3604f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:30:12.227220Z",
     "iopub.status.busy": "2025-04-14T19:30:12.226920Z",
     "iopub.status.idle": "2025-04-14T19:30:12.235744Z",
     "shell.execute_reply": "2025-04-14T19:30:12.234885Z"
    },
    "papermill": {
     "duration": 0.021634,
     "end_time": "2025-04-14T19:30:12.237216",
     "exception": false,
     "start_time": "2025-04-14T19:30:12.215582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate NER Accuracy\n",
    "def evaluate_ner(sample_size=50):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for _, row in sample_df.sample(sample_size).iterrows():\n",
    "        entities = row['entities']\n",
    "        \n",
    "        # Count non-empty entity lists as correct\n",
    "        if len(entities) > 0:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return correct / total\n",
    "    \n",
    "# Run and print accuracy\n",
    "ner_accuracy = evaluate_ner()\n",
    "print(f\"NER Accuracy: {ner_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e8bed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:30:12.258621Z",
     "iopub.status.busy": "2025-04-14T19:30:12.258326Z",
     "iopub.status.idle": "2025-04-14T19:30:12.266701Z",
     "shell.execute_reply": "2025-04-14T19:30:12.265753Z"
    },
    "papermill": {
     "duration": 0.020249,
     "end_time": "2025-04-14T19:30:12.268176",
     "exception": false,
     "start_time": "2025-04-14T19:30:12.247927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Generation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Question Generation Accuracy\n",
    "def evaluate_question_generation(sample_size=20):\n",
    "    good_questions = 0\n",
    "    total_questions = 0\n",
    "    \n",
    "    for _, row in sample_df.sample(sample_size).iterrows():\n",
    "        for question in row['questions']:\n",
    "            # 1. Is the question grammatically correct?\n",
    "            # 2. Is it relevant to the abstract?\n",
    "            # 3. Does it make sense given the keyword?\n",
    "            if not question.startswith(\"Error\"):\n",
    "                good_questions += 1\n",
    "            total_questions += 1\n",
    "    \n",
    "    return good_questions / total_questions if total_questions > 0 else 0\n",
    "\n",
    "qg_accuracy = evaluate_question_generation()\n",
    "print(f\"Question Generation Accuracy: {qg_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a0384ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:30:12.289698Z",
     "iopub.status.busy": "2025-04-14T19:30:12.289349Z",
     "iopub.status.idle": "2025-04-14T19:30:12.294373Z",
     "shell.execute_reply": "2025-04-14T19:30:12.293556Z"
    },
    "papermill": {
     "duration": 0.017221,
     "end_time": "2025-04-14T19:30:12.295644",
     "exception": false,
     "start_time": "2025-04-14T19:30:12.278423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Pipeline Accuracy Estimate: 95.80%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Overall Pipeline Accuracy Estimate\n",
    "overall_accuracy = (\n",
    "    0.4 * keyword_accuracy + \n",
    "    0.3 * ner_accuracy + \n",
    "    0.3 * qg_accuracy\n",
    ")\n",
    "\n",
    "print(f\"\\nOverall Pipeline Accuracy Estimate: {overall_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 612177,
     "sourceId": 11382540,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 660.202711,
   "end_time": "2025-04-14T19:30:15.327616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T19:19:15.124905",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "017c046af3624d11b6691df2c31131e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9bd37dda10b24d3caa54d61cc48af3e6",
       "max": 242013376.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bcfc8253e3d84540b9fb285598f6711e",
       "tabbable": null,
       "tooltip": null,
       "value": 242013376.0
      }
     },
     "01a5b82e3b434e2d80b5bcf9a22e486b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "02989fa765bc4e10bfd59a8162b9902f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06fc74d2bacd427cb63ae6b8637a00fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8ceec2b2443841549a3c50dec7ff29a7",
       "placeholder": "​",
       "style": "IPY_MODEL_8225adc999a44fe79c6958176af05e9f",
       "tabbable": null,
       "tooltip": null,
       "value": " 242M/242M [00:02&lt;00:00, 130MB/s]"
      }
     },
     "0a161d4cabc4492fac74c0e21bad45ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0be54435d5bb4f69816b535d3cc6ad71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18aa61ddbc114bcc98d08a501e615859",
       "placeholder": "​",
       "style": "IPY_MODEL_e4ac0f59b2b7437892262b88681a8e5d",
       "tabbable": null,
       "tooltip": null,
       "value": " 656/656 [00:00&lt;00:00, 65.9kB/s]"
      }
     },
     "0c55023c4e564e99a1f5da598dd7a5dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3c05031556284c1ba41b5552a70237db",
       "placeholder": "​",
       "style": "IPY_MODEL_63e800b81d3642098ba3b94b27b24ee6",
       "tabbable": null,
       "tooltip": null,
       "value": " 31.0/31.0 [00:00&lt;00:00, 3.16kB/s]"
      }
     },
     "0e315d6780464d099f257c7683691f03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "170cc55dd7d642c5afe5f9e56c036d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17cba84d5dd945feb9d3c59c4523fdd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_822d61a883634e3fa8e5bcd368fc9274",
        "IPY_MODEL_60186d1dc80848f9b82eff0d6845bfc3",
        "IPY_MODEL_0c55023c4e564e99a1f5da598dd7a5dc"
       ],
       "layout": "IPY_MODEL_44309d80ff12452a9dc0a64166d94e30",
       "tabbable": null,
       "tooltip": null
      }
     },
     "18aa61ddbc114bcc98d08a501e615859": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a86e9728cbe47cebf0f68376ba79f0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_90353df9608444a792627efdb05d976f",
        "IPY_MODEL_56e46d408d6d414db209868c1ce42c9d",
        "IPY_MODEL_37821f20241341bb9a4345e05670b1b4"
       ],
       "layout": "IPY_MODEL_170cc55dd7d642c5afe5f9e56c036d41",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1af7df5f43d14c088cdad5cb68c0032a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2367d4006cb44924adce40c1edcabf29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "245cab61f187482194870188094df3d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "264252f3a2e94ffc898adc493a45f398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27cf743e0add496d8e371d18530c5939": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d7ef17b8a674f67a7dd7583ee847021": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2dc8e9afa1114c3f86ba8ec682e2c82d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_72dd6f5b2389424babf2841fc9f81540",
       "placeholder": "​",
       "style": "IPY_MODEL_bb80b5d9ffc849248478fffefaa735c4",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "36883f0025b5488f85b0ef43f339655e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "37821f20241341bb9a4345e05670b1b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_27cf743e0add496d8e371d18530c5939",
       "placeholder": "​",
       "style": "IPY_MODEL_2367d4006cb44924adce40c1edcabf29",
       "tabbable": null,
       "tooltip": null,
       "value": " 792k/792k [00:00&lt;00:00, 10.0MB/s]"
      }
     },
     "37b75e4543264b9ba797cd8e3e660ce9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c05031556284c1ba41b5552a70237db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d06090d05784c69a764f4eadae9963e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4082d298ead14a278a607bb77b25d1e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_deb7d454233749c082c239557a7b376b",
        "IPY_MODEL_43db0b688ab348cb9628a4d3aa055e78",
        "IPY_MODEL_adcb5c8a70a24b9082d26201ebc44869"
       ],
       "layout": "IPY_MODEL_0a161d4cabc4492fac74c0e21bad45ac",
       "tabbable": null,
       "tooltip": null
      }
     },
     "42051aa8d8914f5ca08fe9ef0bb79a5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1af7df5f43d14c088cdad5cb68c0032a",
       "placeholder": "​",
       "style": "IPY_MODEL_a67d0f18d6e646d5894b12a6f3eae248",
       "tabbable": null,
       "tooltip": null,
       "value": " 65.0/65.0 [00:00&lt;00:00, 5.39kB/s]"
      }
     },
     "43db0b688ab348cb9628a4d3aa055e78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_719f3ef1cd0a4036a5af59db95425e7f",
       "max": 90.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aeea737a3a2d4393b463ed3296da4904",
       "tabbable": null,
       "tooltip": null,
       "value": 90.0
      }
     },
     "44309d80ff12452a9dc0a64166d94e30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45ad921296aa4e8d8dd008873d5a39b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f9713f9f55764468a9a7e7ef7b70ad6b",
        "IPY_MODEL_a61baba5b643411fb0e27a1754d6b536",
        "IPY_MODEL_0be54435d5bb4f69816b535d3cc6ad71"
       ],
       "layout": "IPY_MODEL_5b7c846c419c4d188fff2bb6b1917e1d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "465f51cda51747d3a00a4ec2a6105558": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "46bdb89c34434984bf23fc77e1cfd235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "542f2d2b39a6493b8300b54fb7cc7e01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56e46d408d6d414db209868c1ce42c9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02989fa765bc4e10bfd59a8162b9902f",
       "max": 791656.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_465f51cda51747d3a00a4ec2a6105558",
       "tabbable": null,
       "tooltip": null,
       "value": 791656.0
      }
     },
     "581956aab2684fa5967fa7828c141f3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "58b5d5cbfc424790aa54e807f1553d1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2dc8e9afa1114c3f86ba8ec682e2c82d",
        "IPY_MODEL_a67c94668a5848ed97074dd6577ac298",
        "IPY_MODEL_42051aa8d8914f5ca08fe9ef0bb79a5f"
       ],
       "layout": "IPY_MODEL_5b501e3870874ef3988676ba07054bda",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5ae9f26da1c84d718edfd2aa66ce2b2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b501e3870874ef3988676ba07054bda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b7c846c419c4d188fff2bb6b1917e1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b955a2dd5aa4f8194230188088767e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60186d1dc80848f9b82eff0d6845bfc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9d84843eef541e3ad098785d8c193a0",
       "max": 31.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_245cab61f187482194870188094df3d3",
       "tabbable": null,
       "tooltip": null,
       "value": 31.0
      }
     },
     "622d9b4fc3c9463d9b4bc3a76d47d266": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "63e800b81d3642098ba3b94b27b24ee6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "719f3ef1cd0a4036a5af59db95425e7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72dd6f5b2389424babf2841fc9f81540": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "735e0d037ada4f68a1a7406b6c90b7b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b4336027988b4005baaec309a3c032d1",
       "placeholder": "​",
       "style": "IPY_MODEL_cd216741abfe485a81292760268c3f56",
       "tabbable": null,
       "tooltip": null,
       "value": " 242M/242M [00:01&lt;00:00, 256MB/s]"
      }
     },
     "8225adc999a44fe79c6958176af05e9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "822d61a883634e3fa8e5bcd368fc9274": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b955a2dd5aa4f8194230188088767e2",
       "placeholder": "​",
       "style": "IPY_MODEL_eff98bb5b590437bba8f0497203cf494",
       "tabbable": null,
       "tooltip": null,
       "value": "added_tokens.json: 100%"
      }
     },
     "8bb05664aaa04cfb95af4fd6539834be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8c612c4b546140e99727aca027bc4ad7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ceec2b2443841549a3c50dec7ff29a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90353df9608444a792627efdb05d976f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_37b75e4543264b9ba797cd8e3e660ce9",
       "placeholder": "​",
       "style": "IPY_MODEL_36883f0025b5488f85b0ef43f339655e",
       "tabbable": null,
       "tooltip": null,
       "value": "spiece.model: 100%"
      }
     },
     "93883d393a45490dba64ff04630ccec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bd37dda10b24d3caa54d61cc48af3e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bfdba7c9d4a4b5fa1149e6b66adac9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c5bf93d3f63c425c90a55baf17f611af",
       "max": 241989808.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_622d9b4fc3c9463d9b4bc3a76d47d266",
       "tabbable": null,
       "tooltip": null,
       "value": 241989808.0
      }
     },
     "a61baba5b643411fb0e27a1754d6b536": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_93883d393a45490dba64ff04630ccec2",
       "max": 656.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_581956aab2684fa5967fa7828c141f3b",
       "tabbable": null,
       "tooltip": null,
       "value": 656.0
      }
     },
     "a67c94668a5848ed97074dd6577ac298": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_264252f3a2e94ffc898adc493a45f398",
       "max": 65.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8c612c4b546140e99727aca027bc4ad7",
       "tabbable": null,
       "tooltip": null,
       "value": 65.0
      }
     },
     "a67d0f18d6e646d5894b12a6f3eae248": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aadf7320762a4013914f247aa3ddd377": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac3d72c4bf7a47bebbd3d46216af059c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ad0e62a337d4413d9ab4d5b932e5ca8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_46bdb89c34434984bf23fc77e1cfd235",
       "placeholder": "​",
       "style": "IPY_MODEL_2d7ef17b8a674f67a7dd7583ee847021",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "adcb5c8a70a24b9082d26201ebc44869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_01a5b82e3b434e2d80b5bcf9a22e486b",
       "placeholder": "​",
       "style": "IPY_MODEL_ed86fba98c1d4b62941dda250a5878cb",
       "tabbable": null,
       "tooltip": null,
       "value": " 90.0/90.0 [00:00&lt;00:00, 4.97kB/s]"
      }
     },
     "aeea737a3a2d4393b463ed3296da4904": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b4336027988b4005baaec309a3c032d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb80b5d9ffc849248478fffefaa735c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bcfc8253e3d84540b9fb285598f6711e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c5bf93d3f63c425c90a55baf17f611af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "caed83a660344401b6b8e1db76bc97e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5ae9f26da1c84d718edfd2aa66ce2b2e",
       "placeholder": "​",
       "style": "IPY_MODEL_ac3d72c4bf7a47bebbd3d46216af059c",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "cd216741abfe485a81292760268c3f56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "deb7d454233749c082c239557a7b376b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aadf7320762a4013914f247aa3ddd377",
       "placeholder": "​",
       "style": "IPY_MODEL_8bb05664aaa04cfb95af4fd6539834be",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "e4ac0f59b2b7437892262b88681a8e5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e67b67aab2f64133bccc457519e09a9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad0e62a337d4413d9ab4d5b932e5ca8a",
        "IPY_MODEL_9bfdba7c9d4a4b5fa1149e6b66adac9a",
        "IPY_MODEL_06fc74d2bacd427cb63ae6b8637a00fc"
       ],
       "layout": "IPY_MODEL_effee346f43447dc9ab4c4d1e91e82b1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ed86fba98c1d4b62941dda250a5878cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eff98bb5b590437bba8f0497203cf494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "effee346f43447dc9ab4c4d1e91e82b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f814308c972b4e2581a318a65819294d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_caed83a660344401b6b8e1db76bc97e2",
        "IPY_MODEL_017c046af3624d11b6691df2c31131e5",
        "IPY_MODEL_735e0d037ada4f68a1a7406b6c90b7b0"
       ],
       "layout": "IPY_MODEL_3d06090d05784c69a764f4eadae9963e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f9713f9f55764468a9a7e7ef7b70ad6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_542f2d2b39a6493b8300b54fb7cc7e01",
       "placeholder": "​",
       "style": "IPY_MODEL_0e315d6780464d099f257c7683691f03",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "f9d84843eef541e3ad098785d8c193a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
